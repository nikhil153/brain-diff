{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "project_dir = \"../\"\n",
    "data_dir = \"/home/nikhil/projects/brain_changes/data/ukbb/\"\n",
    "\n",
    "freesurfer_csv = f\"{data_dir}imaging/freesurfer/ukb47552_followup_subset.csv\"\n",
    "\n",
    "train_csv = f\"{project_dir}metadata/metadata_train.csv\"\n",
    "test_csv = f\"{project_dir}metadata/metadata_test.csv\"\n",
    "\n",
    "freesurfer_fields = f\"{project_dir}/metadata/ukbb_freesurfer_fields.txt\"\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "freesurfer_fields_df = pd.read_csv(freesurfer_fields,sep=\"\t\")\n",
    "freesurfer_fields_df[\"phenotype\"] = freesurfer_fields_df[\"Description\"].str.split(\" \",1,expand=True)[0]\n",
    "freesurfer_fields_df[\"phenotype\"] = freesurfer_fields_df[\"phenotype\"].replace({\"Mean\":\"Mean Thickness\"})\n",
    "CT_fields = freesurfer_fields_df[freesurfer_fields_df[\"phenotype\"]==\"Mean Thickness\"][\"Field ID\"]\n",
    "volume_fields = freesurfer_fields_df[freesurfer_fields_df[\"phenotype\"]==\"Volume\"][\"Field ID\"]\n",
    "\n",
    "print(f\"number of CT fields: {len(CT_fields)}, volume fields: {len(volume_fields)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of CT fields: 62, volume fields: 62\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "pheno_fields = CT_fields # + volume_fields\n",
    "pheno_cols_ses2 = list(pheno_fields.astype(str) + \"-2.0\")\n",
    "pheno_cols_ses3 = list(pheno_fields.astype(str) + \"-3.0\")\n",
    "usecols = [\"eid\"] + pheno_cols_ses2 + pheno_cols_ses3\n",
    "\n",
    "print(f\"reading {len(usecols)} columes\")\n",
    "\n",
    "freesurfer_df = pd.read_csv(freesurfer_csv, usecols=usecols)\n",
    "\n",
    "# Remove eids with missing 2nd or 3rd ses data\n",
    "eid_missing_data = freesurfer_df[freesurfer_df.isna().any(axis=1)][\"eid\"].values\n",
    "print(f\"number participants missing 2nd or 3rd ses freesurfer data: {len(eid_missing_data)}\")\n",
    "\n",
    "freesurfer_df = freesurfer_df[~freesurfer_df[\"eid\"].isin(eid_missing_data)]\n",
    "freesurfer_eids = freesurfer_df[\"eid\"].values\n",
    "\n",
    "print(f\"available freesurfer subjects: {len(freesurfer_eids)}\")\n",
    "\n",
    "freesurfer_df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "reading 125 columes\n",
      "number participants missing 2nd or 3rd ses freesurfer data: 63\n",
      "available freesurfer subjects: 3237\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       eid  27174-2.0  27174-3.0  27175-2.0  27175-3.0  27176-2.0  27176-3.0  \\\n",
       "0  1000635      2.786      2.874      2.910      2.852      2.275      2.307   \n",
       "1  1008391      3.191      2.875      3.080      3.037      2.273      2.143   \n",
       "2  1010129      2.329      1.870      2.836      2.798      1.995      1.943   \n",
       "3  1010994      2.785      2.581      2.671      2.603      2.060      1.819   \n",
       "4  1013774      2.963      3.191      2.617      2.856      2.035      2.050   \n",
       "\n",
       "   27177-2.0  27177-3.0  27178-2.0  ...  27293-2.0  27293-3.0  27294-2.0  \\\n",
       "0      3.389      3.379      2.836  ...      2.387      2.435      2.967   \n",
       "1      3.004      2.571      2.846  ...      2.588      2.592      3.073   \n",
       "2      3.302      3.193      2.812  ...      2.376      2.395      3.081   \n",
       "3      3.144      3.225      2.793  ...      2.513      2.416      2.919   \n",
       "4      2.751      3.385      2.830  ...      2.274      2.403      3.041   \n",
       "\n",
       "   27294-3.0  27295-2.0  27295-3.0  27296-2.0  27296-3.0  27297-2.0  27297-3.0  \n",
       "0      2.958      2.707      2.628      2.229      2.142      2.875      2.750  \n",
       "1      2.859      2.839      2.770      3.086      3.322      3.255      3.003  \n",
       "2      3.086      2.993      2.945      3.016      3.032      3.193      3.168  \n",
       "3      2.881      2.654      2.581      2.088      2.161      2.912      2.866  \n",
       "4      3.008      2.635      2.737      2.527      2.696      2.983      3.263  \n",
       "\n",
       "[5 rows x 125 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>27174-2.0</th>\n",
       "      <th>27174-3.0</th>\n",
       "      <th>27175-2.0</th>\n",
       "      <th>27175-3.0</th>\n",
       "      <th>27176-2.0</th>\n",
       "      <th>27176-3.0</th>\n",
       "      <th>27177-2.0</th>\n",
       "      <th>27177-3.0</th>\n",
       "      <th>27178-2.0</th>\n",
       "      <th>...</th>\n",
       "      <th>27293-2.0</th>\n",
       "      <th>27293-3.0</th>\n",
       "      <th>27294-2.0</th>\n",
       "      <th>27294-3.0</th>\n",
       "      <th>27295-2.0</th>\n",
       "      <th>27295-3.0</th>\n",
       "      <th>27296-2.0</th>\n",
       "      <th>27296-3.0</th>\n",
       "      <th>27297-2.0</th>\n",
       "      <th>27297-3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000635</td>\n",
       "      <td>2.786</td>\n",
       "      <td>2.874</td>\n",
       "      <td>2.910</td>\n",
       "      <td>2.852</td>\n",
       "      <td>2.275</td>\n",
       "      <td>2.307</td>\n",
       "      <td>3.389</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.836</td>\n",
       "      <td>...</td>\n",
       "      <td>2.387</td>\n",
       "      <td>2.435</td>\n",
       "      <td>2.967</td>\n",
       "      <td>2.958</td>\n",
       "      <td>2.707</td>\n",
       "      <td>2.628</td>\n",
       "      <td>2.229</td>\n",
       "      <td>2.142</td>\n",
       "      <td>2.875</td>\n",
       "      <td>2.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1008391</td>\n",
       "      <td>3.191</td>\n",
       "      <td>2.875</td>\n",
       "      <td>3.080</td>\n",
       "      <td>3.037</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.143</td>\n",
       "      <td>3.004</td>\n",
       "      <td>2.571</td>\n",
       "      <td>2.846</td>\n",
       "      <td>...</td>\n",
       "      <td>2.588</td>\n",
       "      <td>2.592</td>\n",
       "      <td>3.073</td>\n",
       "      <td>2.859</td>\n",
       "      <td>2.839</td>\n",
       "      <td>2.770</td>\n",
       "      <td>3.086</td>\n",
       "      <td>3.322</td>\n",
       "      <td>3.255</td>\n",
       "      <td>3.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010129</td>\n",
       "      <td>2.329</td>\n",
       "      <td>1.870</td>\n",
       "      <td>2.836</td>\n",
       "      <td>2.798</td>\n",
       "      <td>1.995</td>\n",
       "      <td>1.943</td>\n",
       "      <td>3.302</td>\n",
       "      <td>3.193</td>\n",
       "      <td>2.812</td>\n",
       "      <td>...</td>\n",
       "      <td>2.376</td>\n",
       "      <td>2.395</td>\n",
       "      <td>3.081</td>\n",
       "      <td>3.086</td>\n",
       "      <td>2.993</td>\n",
       "      <td>2.945</td>\n",
       "      <td>3.016</td>\n",
       "      <td>3.032</td>\n",
       "      <td>3.193</td>\n",
       "      <td>3.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1010994</td>\n",
       "      <td>2.785</td>\n",
       "      <td>2.581</td>\n",
       "      <td>2.671</td>\n",
       "      <td>2.603</td>\n",
       "      <td>2.060</td>\n",
       "      <td>1.819</td>\n",
       "      <td>3.144</td>\n",
       "      <td>3.225</td>\n",
       "      <td>2.793</td>\n",
       "      <td>...</td>\n",
       "      <td>2.513</td>\n",
       "      <td>2.416</td>\n",
       "      <td>2.919</td>\n",
       "      <td>2.881</td>\n",
       "      <td>2.654</td>\n",
       "      <td>2.581</td>\n",
       "      <td>2.088</td>\n",
       "      <td>2.161</td>\n",
       "      <td>2.912</td>\n",
       "      <td>2.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1013774</td>\n",
       "      <td>2.963</td>\n",
       "      <td>3.191</td>\n",
       "      <td>2.617</td>\n",
       "      <td>2.856</td>\n",
       "      <td>2.035</td>\n",
       "      <td>2.050</td>\n",
       "      <td>2.751</td>\n",
       "      <td>3.385</td>\n",
       "      <td>2.830</td>\n",
       "      <td>...</td>\n",
       "      <td>2.274</td>\n",
       "      <td>2.403</td>\n",
       "      <td>3.041</td>\n",
       "      <td>3.008</td>\n",
       "      <td>2.635</td>\n",
       "      <td>2.737</td>\n",
       "      <td>2.527</td>\n",
       "      <td>2.696</td>\n",
       "      <td>2.983</td>\n",
       "      <td>3.263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 125 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_df = pd.read_csv(train_csv)\n",
    "train_eids = train_df[\"eid\"]\n",
    "train_eids_avail = set(train_eids) & set(freesurfer_eids)\n",
    "train_df = pd.merge(train_df, freesurfer_df, on=\"eid\", how=\"inner\")\n",
    "\n",
    "test_df = pd.read_csv(test_csv)\n",
    "test_eids = test_df[\"eid\"]\n",
    "test_eids_avail = set(test_eids) & set(freesurfer_eids)\n",
    "test_df = pd.merge(test_df, freesurfer_df, on=\"eid\", how=\"inner\")\n",
    "\n",
    "print(f\"train samples: {len(train_eids)}, freesurfer data available: {len(train_eids_avail)}, overlap: {len(train_df)}\")\n",
    "print(f\"test samples: {len(test_eids)}, freesurfer data available: {len(test_eids_avail)}, overlap: {len(test_df)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train samples: 2145, freesurfer data available: 1909, overlap: 1909\n",
      "test samples: 1057, freesurfer data available: 958, overlap: 958\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    map_location=lambda storage, loc: storage.cuda()\n",
    "else:\n",
    "    map_location='cpu'\n",
    "    \n",
    "class UKBB_ROI_Dataset_simple(Dataset):\n",
    "    ''' UKBB ROI Dataset comprsing FreeSurfer output\n",
    "    '''\n",
    "\n",
    "    def __init__(self, data_df, pheno_cols, transform=None):\n",
    "        self.data_df = data_df \n",
    "        self.pheno_cols = pheno_cols\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        n_samples = len(self.data_df)\n",
    "        return n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        _df = self.data_df.copy()\n",
    "        eid = _df.loc[idx,\"eid\"]\n",
    "        age_ses2 = _df[_df[\"eid\"]==eid][\"age_at_ses2\"].values[0]   \n",
    "        \n",
    "        X_baseline = _df[_df[\"eid\"]==eid][self.pheno_cols].values\n",
    "\n",
    "        y_baseline = age_ses2/100\n",
    "        y_baseline = np.expand_dims(y_baseline,0)\n",
    "\n",
    "        input_tensor = torch.tensor(X_baseline,dtype=torch.float32)\n",
    "        output_tensor = torch.tensor(y_baseline,dtype=torch.float32)\n",
    "\n",
    "        return eid, input_tensor, output_tensor\n",
    "\n",
    "\n",
    "class UKBB_ROI_Dataset(Dataset):\n",
    "    ''' UKBB ROI Dataset comprsing FreeSurfer output\n",
    "    '''\n",
    "\n",
    "    def __init__(self, data_df, pheno_cols_ses2, pheno_cols_ses3, transform=None):\n",
    "        self.data_df = data_df \n",
    "        self.pheno_cols_ses2 = pheno_cols_ses2\n",
    "        self.pheno_cols_ses3 = pheno_cols_ses3\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        n_samples = len(self.data_df)\n",
    "        return n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        _df = self.data_df.copy()\n",
    "        eid = _df.loc[idx,\"eid\"]\n",
    "        age_ses2 = _df[_df[\"eid\"]==eid][\"age_at_ses2\"].values[0]\n",
    "        age_ses3 = _df[_df[\"eid\"]==eid][\"age_at_ses3\"].values[0]    \n",
    "        \n",
    "        X_baseline = _df[_df[\"eid\"]==eid][self.pheno_cols_ses2].values\n",
    "        X_followup = _df[_df[\"eid\"]==eid][self.pheno_cols_ses3].values\n",
    "\n",
    "        # input1 = np.expand_dims(input1,0)\n",
    "        # input2 = np.expand_dims(input2,0)\n",
    "\n",
    "        y_baseline = age_ses2/100\n",
    "        y_followup = age_ses3/100\n",
    "        y_baseline = np.expand_dims(y_baseline,0)\n",
    "        y_followup = np.expand_dims(y_followup,0)\n",
    "\n",
    "        input_tensor = (torch.tensor(X_baseline,dtype=torch.float32), torch.tensor(X_followup,dtype=torch.float32))\n",
    "        output_tensor = (torch.tensor(y_baseline,dtype=torch.float32), torch.tensor(y_followup,dtype=torch.float32))\n",
    "\n",
    "        return eid, input_tensor, output_tensor\n",
    "\n",
    "\n",
    "class simple_FF(nn.Module):\n",
    "    def __init__(self, input_size,hidden_size,output_size=1):\n",
    "        super(simple_FF, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
    "        # self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "    \n",
    "        self.fcOut = nn.Linear(self.hidden_size, output_size)\n",
    "\n",
    "        # self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x1):\n",
    "        # lower twin branches\n",
    "        x1 =  self.fc1(x1)\n",
    "        # x1 =  self.fc2(x1)\n",
    "    \n",
    "        xout = self.fcOut(x1)\n",
    "    \n",
    "        return xout\n",
    "\n",
    "# Toy network for testing siamese arch\n",
    "class LSN_FF(nn.Module):\n",
    "    def __init__(self, input_size,hidden_size,output_size=1):\n",
    "        super(LSN_FF, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc3 = nn.Linear(2*self.hidden_size, self.hidden_size) #concat\n",
    "        self.fc4 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc5 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc6 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "    \n",
    "        self.fcOut = nn.Linear(self.hidden_size, output_size)\n",
    "\n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # print(f\"x1 shape: {x1.shape}, x2 shape: {x2.shape}\")\n",
    "\n",
    "        # lower twin branches\n",
    "        x1 = self.fc1(x1)\n",
    "        x2 = self.fc1(x2)\n",
    "\n",
    "        x = torch.cat([x1,x2],dim=2)\n",
    "        \n",
    "        # print(f\"concat shape: {x.shape}\")\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # predict (don't want sigmoid!)\n",
    "        x3 = self.fcOut(x)\n",
    "        x4 = self.fcOut(x)\n",
    "    \n",
    "        x_out = torch.cat([x3,x4],dim=2)\n",
    "\n",
    "        return x_out\n",
    "\n",
    "def train(model, train_dataloader, optimizer, criterion, n_epochs):\n",
    "    batch_loss_list = []\n",
    "    epoch_loss_list = []\n",
    "    preds_df = pd.DataFrame()\n",
    "    # model.train()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        print(\"Starting epoch \" + str(epoch+1))    \n",
    "            \n",
    "        batch_idx = 0\n",
    "        for eids, inputs, outputs in train_dataloader:\n",
    "            img1 = inputs\n",
    "    \n",
    "            age_at_ses2 = outputs\n",
    "            img1 = img1.to(device)\n",
    "        \n",
    "            age_at_ses2 = age_at_ses2.to(device)\n",
    "                        \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            preds = model(img1)\n",
    "            \n",
    "            p_df = pd.DataFrame()\n",
    "            p_df[\"eid\"] = eids\n",
    "            p_df[\"pred_baseline\"] = np.vstack(preds.detach().numpy())\n",
    "            p_df[\"epoch\"] = epoch\n",
    "            p_df[\"batch_idx\"] = batch_idx\n",
    "            \n",
    "            preds_df = preds_df.append(p_df)\n",
    "            \n",
    "            loss = criterion(preds[:,:,0],age_at_ses2)\n",
    "            # loss = twinLoss(preds[:,:,0], preds[:,:,1], age_at_ses2, age_at_ses3, criterion) \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            batch_loss_list.append(loss.item())\n",
    "            # print(f\"running loss: {running_loss}\")\n",
    "            batch_idx = batch_idx + 1\n",
    "        \n",
    "        \n",
    "        epoch_loss = running_loss/len(train_dataloader)\n",
    "        epoch_loss_list.append(epoch_loss)\n",
    "        print(f\"epoch {epoch} loss: {epoch_loss:5.4f}\")\n",
    "\n",
    "    print(f\"epoch {epoch} loss: {epoch_loss:5.4f}\")\n",
    "\n",
    "    ## loss df\n",
    "    batch_loss_df = pd.DataFrame()\n",
    "    batch_loss_df[\"batch_loss\"] = batch_loss_list\n",
    "\n",
    "    epoch_loss_df = pd.DataFrame()\n",
    "    epoch_loss_df[\"epoch_loss\"] = epoch_loss_list\n",
    "\n",
    "    return model, batch_loss_df, epoch_loss_df, preds_df\n",
    "\n",
    "\n",
    "def train_simple(model, train_df, pheno_cols_ses2, optimizer, criterion, n_epochs):\n",
    "    batch_loss_list = []\n",
    "    epoch_loss_list = []\n",
    "    preds_df = pd.DataFrame()\n",
    "    # model.train()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        print(\"Starting epoch \" + str(epoch+1))    \n",
    "\n",
    "        n_samples = len(train_df)\n",
    "            \n",
    "        batch_idx = 0\n",
    "        for i in range(n_samples):\n",
    "            eids = train_df.loc[i,\"eid\"]\n",
    "            img1 = train_df.loc[i,pheno_cols_ses2].values.astype(np.float32)            \n",
    "            age_at_ses2 = train_df.loc[i,\"age_at_ses2\"] / 100\n",
    "\n",
    "            img1 = torch.tensor(img1,dtype=torch.float32)\n",
    "            age_at_ses2 = torch.tensor(age_at_ses2,dtype=torch.float32)\n",
    "\n",
    "            img1 = img1.to(device)\n",
    "            age_at_ses2 = age_at_ses2.to(device)\n",
    "                        \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            preds = model(img1)\n",
    "                        \n",
    "            loss = criterion(preds,age_at_ses2)\n",
    "            # loss = twinLoss(preds[:,:,0], preds[:,:,1], age_at_ses2, age_at_ses3, criterion) \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            p_df = pd.DataFrame()\n",
    "            p_df[\"eid\"] = eids\n",
    "            p_df[\"pred_baseline\"] = 100*np.squeeze(np.vstack(preds.detach().numpy()))\n",
    "            p_df[\"epoch\"] = epoch\n",
    "            p_df[\"batch_idx\"] = batch_idx\n",
    "            \n",
    "            preds_df = preds_df.append(p_df)\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            batch_loss_list.append(loss.item())\n",
    "            # print(f\"running loss: {running_loss}\")\n",
    "            batch_idx = batch_idx + 1\n",
    "                \n",
    "        epoch_loss = running_loss/n_samples\n",
    "        epoch_loss_list.append(epoch_loss)\n",
    "        print(f\"epoch {epoch} loss: {epoch_loss:5.4f}\")\n",
    "\n",
    "    print(f\"epoch {epoch} loss: {epoch_loss:5.4f}\")\n",
    "\n",
    "    ## loss df\n",
    "    batch_loss_df = pd.DataFrame()\n",
    "    batch_loss_df[\"batch_loss\"] = batch_loss_list\n",
    "\n",
    "    epoch_loss_df = pd.DataFrame()\n",
    "    epoch_loss_df[\"epoch_loss\"] = epoch_loss_list\n",
    "\n",
    "    return model, batch_loss_df, epoch_loss_df, preds_df\n",
    "\n",
    "\n",
    "def train_simple_LSN(model, train_df, pheno_cols_ses2,pheno_cols_ses3, optimizer, criterion, n_epochs):\n",
    "    batch_loss_list = []\n",
    "    epoch_loss_list = []\n",
    "    preds_df = pd.DataFrame()\n",
    "    # model.train()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        print(\"Starting epoch \" + str(epoch+1))    \n",
    "\n",
    "        n_samples = len(train_df)\n",
    "            \n",
    "        batch_idx = 0\n",
    "        for i in range(n_samples):\n",
    "            eids = train_df.loc[i,\"eid\"]\n",
    "            img1 = train_df.loc[i,pheno_cols_ses2].values.astype(np.float32)   \n",
    "            img1 = np.expand_dims(img1,0)\n",
    "            img1 = np.expand_dims(img1,1)  \n",
    "            age_at_ses2 = train_df.loc[i,\"age_at_ses2\"] / 100\n",
    "            age_at_ses2 = np.expand_dims(age_at_ses2,axis=0)\n",
    "            \n",
    "\n",
    "            img2 = train_df.loc[i,pheno_cols_ses3].values.astype(np.float32)   \n",
    "            img2 = np.expand_dims(img2,0)\n",
    "            img2 = np.expand_dims(img2,1)         \n",
    "            age_at_ses3 = train_df.loc[i,\"age_at_ses3\"] / 100\n",
    "            age_at_ses3 = np.expand_dims(age_at_ses3,axis=0)\n",
    "\n",
    "            img1 = torch.tensor(img1,dtype=torch.float32).to(device)\n",
    "            age_at_ses2 = torch.tensor(age_at_ses2,dtype=torch.float32).to(device)    \n",
    "\n",
    "            img2 = torch.tensor(img2,dtype=torch.float32).to(device)\n",
    "            age_at_ses3 = torch.tensor(age_at_ses3,dtype=torch.float32).to(device)\n",
    "            \n",
    "            # print(f\"shapes: {img1.shape}, {img2.shape}, {age_at_ses2.shape}, {age_at_ses3.shape}\")\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            preds = model(img1,img2)\n",
    "                        \n",
    "            loss = twinLoss(preds[:,:,0], preds[:,:,1], age_at_ses2, age_at_ses3, criterion) \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            p_df = pd.DataFrame()\n",
    "            p_df[\"eid\"] = eids\n",
    "            p_df[\"pred_baseline\"] = 100*np.squeeze(np.vstack(preds[:,:,0].detach().numpy()))\n",
    "            p_df[\"pred_followup\"] = 100*np.squeeze(np.vstack(preds[:,:,1].detach().numpy()))\n",
    "            p_df[\"epoch\"] = epoch\n",
    "            p_df[\"batch_idx\"] = batch_idx\n",
    "            \n",
    "            preds_df = preds_df.append(p_df)\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            batch_loss_list.append(loss.item())\n",
    "            # print(f\"running loss: {running_loss}\")\n",
    "            batch_idx = batch_idx + 1\n",
    "        \n",
    "        \n",
    "        epoch_loss = running_loss/n_samples\n",
    "        epoch_loss_list.append(epoch_loss)\n",
    "        print(f\"epoch {epoch} loss: {epoch_loss:5.4f}\")\n",
    "\n",
    "    print(f\"epoch {epoch} loss: {epoch_loss:5.4f}\")\n",
    "\n",
    "    ## loss df\n",
    "    batch_loss_df = pd.DataFrame()\n",
    "    batch_loss_df[\"batch_loss\"] = batch_loss_list\n",
    "\n",
    "    epoch_loss_df = pd.DataFrame()\n",
    "    epoch_loss_df[\"epoch_loss\"] = epoch_loss_list\n",
    "\n",
    "    return model, batch_loss_df, epoch_loss_df, preds_df\n",
    "\n",
    "def twinLoss(x1,x2,y1,y2,loss_func):\n",
    "    \"\"\"Returns twin loss for a given loss func\n",
    "    \"\"\"\n",
    "    loss1 = loss_func(x1,y1)\n",
    "    loss2 = loss_func(x2,y2)\n",
    "    loss = 0.5*(loss1 + loss2)\n",
    "    return loss\n",
    "\n",
    "def test_simple(model, test_dataloader, criterion=nn.L1Loss()):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        eid_list = []\n",
    "        loss1_list = []\n",
    "        y_pred_list = []\n",
    "        y_test_list = []\n",
    "        for eid, inputs, outputs in test_dataloader:\n",
    "            eid_list.append(eid.detach().numpy())\n",
    "            img1 = inputs\n",
    "            age_at_ses2 = 100*outputs \n",
    "            y_test = age_at_ses2\n",
    "            y_test_list.append(y_test)\n",
    "            img1 = img1.to(device)\n",
    "            age_at_ses2 = age_at_ses2.to(device) \n",
    "            \n",
    "            preds = 100*model(img1) #Scale age\n",
    "            y_pred_list.append(preds.detach().numpy())\n",
    "\n",
    "            loss1 = criterion(preds[:,:,0],age_at_ses2)            \n",
    "            loss1_list.append(loss1.item())\n",
    "\n",
    "    return eid_list, y_test_list, y_pred_list, \n",
    "    \n",
    "def test(model, test_dataloader, criterion=nn.L1Loss()):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        eid_list = []\n",
    "        loss1_list = []\n",
    "        loss2_list = []\n",
    "        y_pred_list = []\n",
    "        y_test_list = []\n",
    "        for eid, inputs, outputs in test_dataloader:\n",
    "            eid_list.append(eid.detach().numpy())\n",
    "            img1 = inputs[0]\n",
    "            img2 = inputs[1]\n",
    "\n",
    "            age_at_ses2 = 100*outputs[0] \n",
    "            age_at_ses3 = 100*outputs[1] \n",
    "\n",
    "            y_test = (age_at_ses2,age_at_ses3)\n",
    "            y_test_list.append(y_test)\n",
    "\n",
    "            img1 = img1.to(device)\n",
    "            img2 = img2.to(device)\n",
    "            age_at_ses2 = age_at_ses2.to(device) \n",
    "            age_at_ses3 = age_at_ses3.to(device) \n",
    "            \n",
    "            preds = 100*model(img1, img2) #Scale age\n",
    "            y_pred_list.append(preds.detach().numpy())\n",
    "\n",
    "            loss1 = criterion(preds[:,:,0],age_at_ses2)\n",
    "            loss2 = criterion(preds[:,:,1],age_at_ses3)\n",
    "            \n",
    "            loss1_list.append(loss1.item())\n",
    "            loss2_list.append(loss2.item())\n",
    "\n",
    "    return eid_list, y_test_list, y_pred_list, loss1_list, loss2_list\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# n_samples = 50\n",
    "\n",
    "batch_size = 10\n",
    "transform = None #\"random_swap\" #only for training\n",
    "\n",
    "train_dataset = UKBB_ROI_Dataset_simple(train_df, pheno_cols_ses2, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# iter(train_dataloader).next()\n",
    "print(f\"len train dataset: {len(train_dataset)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len train dataset: 1909\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "n_epochs = 10\n",
    "input_size = len(pheno_cols_ses2)\n",
    "hidden_size = 10\n",
    "lr = 0.001\n",
    "\n",
    "model = LSN_FF(input_size,hidden_size=hidden_size)\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) #optim.SGD(model.parameters(), lr=lr, momentum=0.5)                                                                                               \n",
    "criterion = nn.MSELoss()  #nn.L1Loss() #\n",
    "\n",
    "# using subset of train dataloader for debug\n",
    "# model, batch_loss_df, epoch_loss_df, preds_df = train(model,train_dataloader,optimizer,criterion,n_epochs)\n",
    "# model, batch_loss_df, epoch_loss_df, preds_df = train_simple(model,train_df,pheno_cols_ses2,optimizer,criterion,n_epochs)\n",
    "model, batch_loss_df, epoch_loss_df, preds_df = train_simple_LSN(model,train_df,pheno_cols_ses2,pheno_cols_ses3,optimizer,criterion,n_epochs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/nikhil/projects/green_comp_neuro/green_compute/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0 loss: 0.0090\n",
      "Starting epoch 2\n",
      "epoch 1 loss: 0.0062\n",
      "Starting epoch 3\n",
      "epoch 2 loss: 0.0061\n",
      "Starting epoch 4\n",
      "epoch 3 loss: 0.0062\n",
      "Starting epoch 5\n",
      "epoch 4 loss: 0.0062\n",
      "Starting epoch 6\n",
      "epoch 5 loss: 0.0062\n",
      "Starting epoch 7\n",
      "epoch 6 loss: 0.0066\n",
      "Starting epoch 8\n",
      "epoch 7 loss: 0.0065\n",
      "Starting epoch 9\n",
      "epoch 8 loss: 0.0064\n",
      "Starting epoch 10\n",
      "epoch 9 loss: 0.0067\n",
      "epoch 9 loss: 0.0067\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "plt.plot(epoch_loss_df)\n",
    "epoch_loss_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   epoch_loss\n",
       "0    0.009035\n",
       "1    0.006195\n",
       "2    0.006143\n",
       "3    0.006166\n",
       "4    0.006242"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dfXRc9X3n8fd3ZvRgSSPZlmWNsQ3ygzSuYQskikNIgCROAnTbON0ljdlDSwmNkywkJO3ZXehus1l6OCf0pKUJIemhgZSyJIY6PKhZTkjASfpwUoNsaIINsmUbYxssyw9YT9bzd/+YK3kkS9ZYGulqNJ/XOToz87u/e+d3Bzyfub/fvb9r7o6IiMiQSNgNEBGR2UXBICIiIygYRERkBAWDiIiMoGAQEZERYmE3IBsWLVrkNTU1YTdDRCSnbN++/Zi7V40unxPBUFNTQ2NjY9jNEBHJKWZ2YKxydSWJiMgICgYRERlBwSAiIiMoGEREZAQFg4iIjKBgEBGRERQMIiIyQkbBYGbXmVmTmTWb2Z1jLC8ys8eD5dvMrCZt2V1BeZOZXZtWfoeZvWpmO83sS2nlC83sp2a2J3hcMLVdHN/PXj/Kt3/ePF2bFxHJSRMGg5lFgQeA64G1wI1mtnZUtVuBk+6+GrgPuDdYdy2wEbgYuA74tplFzewS4DPAOuBS4LfNbHWwrTuBF9y9FngheD0t/rX5GN94fg8Dg7onhYjIkEyOGNYBze6+z917gc3AhlF1NgCPBM+3AOvNzILyze7e4+77geZge78BbHP3LnfvB34B/KcxtvUI8InJ7drE6hJxevoHOXC8c7reQkQk52QSDEuBg2mvDwVlY9YJvuhPAZXnWPdV4CozqzSzEuC3gOVBnWp3fzt4fgSoznhvztOaRByA3S3t0/UWIiI5J5TBZ3d/jVR300+AHwOvAANj1HNgzH4eM9tkZo1m1tja2jqpdtQujmMGrx9RMIiIDMkkGA5z5tc8wLKgbMw6ZhYDKoDj51rX3R9y93e7+9XASWB3UKfFzJYE21oCHB2rUe7+oLvXu3t9VdVZkwNmZF5hlIsWluiIQUQkTSbB8BJQa2YrzKyQ1GByw6g6DcDNwfMbgK3Br/0GYGNw1tIKoBZ4EcDMFgePF5IaX/j+GNu6GXhmMjuWqWQiriMGEZE0E0677e79ZnY78BwQBR52951mdjfQ6O4NwEPAo2bWDJwgFR4E9Z4AdgH9wG3uPtRl9EMzqwT6gvJ3gvKvAU+Y2a3AAeD3srWzY0lWx/nprha6+wYoLohO51uJiOSEjO7H4O7PAs+OKvtK2vNu4JPjrHsPcM8Y5VeNU/84sD6TdmVDMlHOoEPz0Q4uWVoxU28rIjJr5f2Vz8ngzKQmdSeJiAAKBmoqSyiMRTQALSISyPtgiEUjrK4q0wC0iEgg74MBUt1J6koSEUlRMJAKhiNt3Zzq6gu7KSIioVMwkDYArXEGEREFA6SuZQAFg4gIKBgAWFJRTLw4RtORtrCbIiISOgUDYGYkqzUALSICCoZhQ2cmpaZ4EhHJXwqGwJpEnLbufo60dYfdFBGRUCkYAnXVmhpDRAQUDMM0Z5KISIqCITC/pJDq8iIFg4jkPQVDmmSiXNcyiEjeUzCkWZOIs+doB/0Dg2E3RUQkNAqGNHXVcXr7BzlwoivspoiIhEbBkGaNBqBFRBQM6VYvLiNi6N4MIpLXFAxpigui1FSWslvBICJ5TMEwSl11XGcmiUheUzCMkkzEeeN4J919A2E3RUQkFAqGUdYk4rjDnpaOsJsiIhIKBcModbqbm4jkOQXDKDWVpRTGIrppj4jkLQXDKNGIUbu4TKesikjeyigYzOw6M2sys2Yzu3OM5UVm9niwfJuZ1aQtuysobzKza9PKv2xmO83sVTP7gZkVB+V/Z2b7zeyV4O+yqe/m+Ukm4uxWV5KI5KkJg8HMosADwPXAWuBGM1s7qtqtwEl3Xw3cB9wbrLsW2AhcDFwHfNvMoma2FPgiUO/ulwDRoN6Q/+bulwV/r0xpDydhTSJOS1sP73T1zvRbi4iELpMjhnVAs7vvc/deYDOwYVSdDcAjwfMtwHozs6B8s7v3uPt+oDnYHkAMmGdmMaAEeGtqu5I9ummPiOSzTIJhKXAw7fWhoGzMOu7eD5wCKsdb190PA18H3gTeBk65+0/S6t1jZr8ys/vMrGisRpnZJjNrNLPG1tbWDHYjc2sS5YDOTBKR/BTK4LOZLSB1NLECuAAoNbObgsV3AWuA9wALgf8x1jbc/UF3r3f3+qqqqqy2r7q8iPLimAagRSQvZRIMh4Hlaa+XBWVj1gm6hiqA4+dY9yPAfndvdfc+4EngSgB3f9tTeoDvcabracaYGWsS5ZozSUTyUibB8BJQa2YrzKyQ1CBxw6g6DcDNwfMbgK3u7kH5xuCspRVALfAiqS6kK8ysJBiLWA+8BmBmS4JHAz4BvDqVHZysZCI1Z1JqN0RE8kdsogru3m9mtwPPkTp76GF332lmdwON7t4APAQ8ambNwAmCM4yCek8Au4B+4DZ3HwC2mdkWYEdQ/jLwYPCWj5lZFWDAK8Dnsre7matLxGnv7uftU91cMH9eGE0QEQmFzYVfxPX19d7Y2JjVbb70xgk++Te/5Ht/+B4+tGZxVrctIjIbmNl2d68fXa4rn8dRtzh1yqoGoEUk3ygYxlFRUsCSimJdAS0ieUfBcA7JRFxHDCKSdxQM55CsjrP3aAf9A4NhN0VEZMYoGM4hmYjTOzDIG8c7w26KiMiMUTCcw9CcSepOEpF8omA4h9WLy4hGTFdAi0heUTCcQ3FBlJrKEh0xiEheUTBMQDftEZF8o2CYQLK6nAMnuujq7Q+7KSIiM0LBMIFkogx32NPSEXZTRERmhIJhAkndtEdE8oyCYQIXLiyhuCCi23yKSN5QMEwgGjFqF2sAWkTyh4IhA5ozSUTyiYIhA8nqOK3tPZzo7A27KSIi007BkIFkIjU1hsYZRCQfKBgycCYY2kJuiYjI9FMwZGBxvIj5JQU06VoGEckDCoYMmBnJ6riOGEQkLygYMpSaM6kDdw+7KSIi00rBkKFkIk5HTz+H3zkddlNERKaVgiFDyWqdmSQi+UHBkKG6oTOTdAW0iMxxCoYMlRcXsHT+PB0xiMicl1EwmNl1ZtZkZs1mducYy4vM7PFg+TYzq0lbdldQ3mRm16aVf9nMdprZq2b2AzMrDspXBNtoDrZZOPXdzI666jIFg4jMeRMGg5lFgQeA64G1wI1mtnZUtVuBk+6+GrgPuDdYdy2wEbgYuA74tplFzWwp8EWg3t0vAaJBPYJ17wu2dTLY9qyQTJSzt7WDvoHBsJsiIjJtMjliWAc0u/s+d+8FNgMbRtXZADwSPN8CrDczC8o3u3uPu+8HmoPtAcSAeWYWA0qAt4J1Phxsg2Cbn5jcrmVfMlFG34Cz/1hn2E0REZk2mQTDUuBg2utDQdmYddy9HzgFVI63rrsfBr4OvAm8DZxy958E67wTbGO89wLAzDaZWaOZNba2tmawG1OXrA5u2qPuJBGZw0IZfDazBaSOJlYAFwClZnbT+WzD3R9093p3r6+qqpqOZp5l1eJSohFTMIjInJZJMBwGlqe9XhaUjVkn6BqqAI6fY92PAPvdvdXd+4AngSuDdeYH2xjvvUJTFIuyYlGp7s0gInNaJsHwElAbnC1USGqQuGFUnQbg5uD5DcBWT80d0QBsDM5aWgHUAi+S6kK6wsxKgnGF9cBrwTo/C7ZBsM1nJr972ZeaGkPBICJz14TBEPT33w48B7wGPOHuO83sbjP7eFDtIaDSzJqBPwbuDNbdCTwB7AJ+DNzm7gPuvo3UAPMO4NdBOx4MtvU/gD8OtlUZbHvWSFbHefNEF509/RNXFhHJQTYXJoWrr6/3xsbGGXmv53Ye4bOPbufp297PZcvnz8h7iohMBzPb7u71o8t15fN5WqOb9ojIHKdgOE/LF5QwryCqAWgRmbMUDOcpEjHqqss0AC0ic5aCYRLqquO6lkFE5iwFwyQkE3GOdfRyrKMn7KaIiGSdgmESksEA9G4dNYjIHKRgmIShYNAAtIjMRQqGSagqK2JhaaEGoEVkTlIwTIJZ6swkHTGIyFykYJikNYly9rS0MziY+1eOi4ikUzBMUl11nM7eAQ6/czrspoiIZJWCYZI0AC0ic5WCYZLqqssANAAtInOOgmGS4sUFLJ0/T0cMIjLnKBimYE0irovcRGTOUTBMQV0izt7WDnr7B8NuiohI1igYpmBNIk7/oLPvWEfYTRERyRoFwxQkh2/ao+4kEZk7FAxTsHJRGbGIKRhEZE5RMExBYSzCyqpSnbIqInOKgmGK6qrjOmVVROYUBcMUrUnEOXTyNB09/WE3RUQkKxQMU5RMlAO6AlpE5g4FwxQlq3VmkojMLQqGKVq2YB4lhVEFg4jMGRkFg5ldZ2ZNZtZsZneOsbzIzB4Plm8zs5q0ZXcF5U1mdm1QljSzV9L+2szsS8Gyr5rZ4bRlv5WdXZ0ekYhRWx1XMIjInBGbqIKZRYEHgI8Ch4CXzKzB3XelVbsVOOnuq81sI3Av8CkzWwtsBC4GLgCeN7M6d28CLkvb/mHgqbTt3efuX5/67s2MNdVxnn+tJexmiIhkRSZHDOuAZnff5+69wGZgw6g6G4BHgudbgPVmZkH5Znfvcff9QHOwvXTrgb3ufmCyOxG2ZCLO8c5eWtt7wm6KiMiUZRIMS4GDaa8PBWVj1nH3fuAUUJnhuhuBH4wqu93MfmVmD5vZgrEaZWabzKzRzBpbW1sz2I3po6kxRGQuCXXw2cwKgY8D/5BW/B1gFamupreBvxxrXXd/0N3r3b2+qqpq2tt6LsPBoFNWRWQOyCQYDgPL014vC8rGrGNmMaACOJ7ButcDO9x9uIPe3VvcfcDdB4G/5eyup1lnUVkRlaWFNB1pC7spIiJTlkkwvATUmtmK4Bf+RqBhVJ0G4Obg+Q3AVnf3oHxjcNbSCqAWeDFtvRsZ1Y1kZkvSXv4u8GqmOxOmZCJOU4um3xaR3DfhWUnu3m9mtwPPAVHgYXffaWZ3A43u3gA8BDxqZs3ACVLhQVDvCWAX0A/c5u4DAGZWSupMp8+Oesu/MLPLAAfeGGP5rFRXHeeJxoMMDjqRiIXdHBGRSZswGADc/Vng2VFlX0l73g18cpx17wHuGaO8k9QA9ejy38+kTbPNmkScrt4BDp7s4qLK0rCbIyIyabryOUt0ZpKIzBUKhiyp1ZxJIjJHKBiypKwoxvKF83TKqojkPAVDFiU1Z5KIzAEKhixKJuLsO9ZJT/9A2E0REZk0BUMWJRPlDAw6+1o7w26KiMikKRiySDftEZG5QMGQRSsWlVIQNQ1Ai0hOUzBkUWEswspFZTpiEJGcpmDIsmRCZyaJSG5TMGRZMhHn8Dunae/uC7spIiKTomDIsqEB6N0aZxCRHKVgyLIzcyZpCm4RyU0KhixbOn8epYVR3bRHRHKWgiHLIhGjLhHndQ1Ai0iOUjBMgzWJOLtb2kndxE5EJLcoGKZBXXWck119tLb3hN0UEZHzpmCYBsMD0DozSURykIJhGmjOJBHJZQqGaVBZVsSisiINQItITlIwTJOhAWgRkVyjYJgmddWpYBgY1JlJIpJbFAzTZE0iTnffIAdPdIXdFBGR86JgmCZ1wZlJGmcQkVyjYJgmddVlgM5MEpHck1EwmNl1ZtZkZs1mducYy4vM7PFg+TYzq0lbdldQ3mRm1wZlSTN7Je2vzcy+FCxbaGY/NbM9weOC7OzqzCopjHHhwhINQItIzpkwGMwsCjwAXA+sBW40s7Wjqt0KnHT31cB9wL3BumuBjcDFwHXAt80s6u5N7n6Zu18GvBvoAp4KtnUn8IK71wIvBK9zUjIR53VNpiciOSaTI4Z1QLO773P3XmAzsGFUnQ3AI8HzLcB6M7OgfLO797j7fqA52F669cBedz8wxrYeAT5xPjs0m6xJxHnjeBfdfQNhN0VEJGOZBMNS4GDa60NB2Zh13L0fOAVUZrjuRuAHaa+r3f3t4PkRoHqsRpnZJjNrNLPG1tbWDHZj5tVVxxkYdPa26t4MIpI7Qh18NrNC4OPAP4y13FPTk455IYC7P+ju9e5eX1VVNY2tnLw1CU2NISK5J5NgOAwsT3u9LCgbs46ZxYAK4HgG614P7HD3lrSyFjNbEmxrCXA0gzbOSjWLSimImibTE5GckkkwvATUmtmK4Bf+RqBhVJ0G4Obg+Q3A1uDXfgOwMThraQVQC7yYtt6NjOxGGr2tm4FnMt2Z2aYgGmFVVZmOGEQkp8QmquDu/WZ2O/AcEAUedvedZnY30OjuDcBDwKNm1gycIBUeBPWeAHYB/cBt7j4AYGalwEeBz456y68BT5jZrcAB4PeysJ+hWZOI8+L+E2E3Q0QkYxMGA4C7Pws8O6rsK2nPu4FPjrPuPcA9Y5R3khqgHl1+nNSZSnNCXSLO06+8xanTfVTMKwi7OSIiE9KVz9NsaABaF7qJSK5QMEyzOt20R0RyjIJhmi2dP494UUzBICI5Q8EwzcyMukRcp6yKSM5QMMyAuuo4TUfaSZ3BKyIyuykYZsCaRJxTp/toaesJuykiIhNSMMyA4QFodSeJSA5QMMyAM3MmaQpuEZn9FAwzYEFpIYvjRTQd0SyrIjL7KRhmSDIRp6lFRwwiMvspGGZIsjrOnpYOBgZ1ZpKIzG4KhhlSl4jT0z/IgeOdYTdFROScFAwzRDftEZFcoWCYIbWL45jplFURmf0UDDNkXmGUixaW6IhBRGY9BcMMSibiCgYRyYo9Le388eOvcLwj+zMqKBhmULI6zhvHO+nuGwi7KSKSo/a0tPOFH7zMx/76n3hu5xF+ffhU1t8jozu4SXYkE+UMOjQf7eCSpRVhN0dEckjz0Xa++UIz//irt5hXEOXz16zij65aycLSwqy/l4JhBiUTZUDqzCQFg4hkovloB/dv3UPDv6cC4XPXrOIz0xQIQxQMM6imspTCWERnJonIhPa2dnD/C6lAKC6I8tmrV7Hp6ukNhCEKhhkUi0ZYXVXG6xqAlhxz8EQXB0908a6LFlBcEA27OXNaeiAUxaJ85uqVbLpqJZVlRTPWBgXDDEsm4vxy7/GwmyGSsS3bD/FnT7/K6b4BimIRrlhZyTV1VVyTrGLlolLMLOwmzgn7Wju4f2szz7xyOLRAGKJgmGHJRJynXj7Mqa4+KkoKwm6OyLi6evv5yjM72bL9EFesXMgt71/Bv+07zi92t3L3j3bBj2DZgnmpkKir4srViygr0lfK+drX2sG3tjbz9FAgXLWSz1y9kkUhBMIQ/VecYcm0m/asW7Ew5NaIjG1PSzv/9bEdNLd28MX1tdyxvpZoxLj24gSQ6lr6xe5WfrG7ladfPsxj294kFjHqaxZwTd1irqmr4jeWxHU0cQ77j3Vy/9Y9PP3yYQpjEf7oqpVsCjkQhigYZlgy7aY9CgaZjX64/RD/6+lXKS2K8uin38sHahedVWf5whJuuuIibrriInr7B9l+4ORwUNz749e598evUxUvGj6a+MDqRSyYgUHTXPDGsU6+mRYIt35gBZuuXkVVPPxAGJJRMJjZdcA3gCjwXXf/2qjlRcDfA+8GjgOfcvc3gmV3AbcCA8AX3f25oHw+8F3gEsCBT7v7L83sq8BngNZg83/q7s9OYR9nlSUVxcSLYxqAllnndO8AX3nmVf4h6Dr65sbLWVxePOF6hbEI71tVyftWVXLn9Wtoaevmn4KQ+OmuFrZsP0TE4NLl84eD4jeXzScaya+jiTeOdXJ/0GVUELVZGQhDJgwGM4sCDwAfBQ4BL5lZg7vvSqt2K3DS3Veb2UbgXuBTZrYW2AhcDFwAPG9mde4+QCpofuzuN5hZIVCStr373P3r2djB2cbMSFbH2a1TVmUW2dPSzm3f38GeoyO7jiajuryYT9Yv55P1yxkYdH516B1+3pQKim+8sIe/fn4P80sKuKq2iqtrF3FNXVVGAZSrDhxPBcJTLx8mFjFuubKGTdesZHF89u5zJkcM64Bmd98HYGabgQ1AejBsAL4aPN8CfMtSnYsbgM3u3gPsN7NmYJ2Z7QKuBv4QwN17gd4p702OSCbiNPz7W7i7+mAldENdRyWFUf7+0+u4qrYqa9uORozLL1zA5Rcu4MsfreNkZy//0nxsuNvpH//9LQB+Y0n58NHEuy9aQGEs92frOXC8k29tbebJIBD+8MoaPjvLA2FIJsGwFDiY9voQ8N7x6rh7v5mdAiqD8n8bte5S4DSprqLvmdmlwHbgDncfuovN7Wb2B0Aj8CfufvK89mqWSybitG/r50hbN0sq5oXdHMlT6V1H712xkG/eeDnV0/zLfUFpIb9z6QX8zqUX4O689nZ7EBJH+e4/7+NvfrGX0sIoV65eNBwUyxeWTLzhWeTN411862d7+OGOVCDc/L4aPvfB3AiEIWENPseAdwFfcPdtZvYN4E7gz4DvAH9Oatzhz4G/BD49egNmtgnYBHDhhRfOULOzY+jMpNePtCsYJBQjuo4+vJovrq8lFp3ZX+lmxtoLyll7QTmf/+Aq2rv7+OXe1OmwP29KjU8ArKwqHQ6JK1ZWztoL7A6e6OL+ralAiEaMP3jfRXz+mlU52U2WSTAcBpanvV4WlI1V55CZxYAKUoPQ4617CDjk7tuC8i2kggF3bxmqbGZ/C/xorEa5+4PAgwD19fU5dSPlZNrd3D6UXBxyayTfTGfX0VTEiwv42MUJPnZxAndn37FOfhGMTXx/25t871/foCgWoaaylIp5BZTPK6BixF+MipKRZUN1imLTFyYHT3Txra3N/HDHISJBIHzumlXTfvQ1nTIJhpeAWjNbQepLfSPwX0bVaQBuBn4J3ABsdXc3swbg+2b2V6QGn2uBF919wMwOmlnS3ZuA9QRjFma2xN3fDrb7u8CrU9vF2Wd+SSHV5UXs1plJMoNO9w7wvxte5YnGmes6miwzY1VVGauqyvj0B1bQ3TfAtv0n+KfdrRw80cWp030cOtnFrrf6OHW6j87ec09lX1wQGRUiZ0KjvHhUwIwKl/GOUA6e6OKBnzWnzrqKGDddcRGf/2BuB8KQCYMhGDO4HXiO1OmqD7v7TjO7G2h09wbgIeDRYHD5BKnwIKj3BKkv/X7gtuCMJIAvAI8FZyTtA24Jyv/CzC4j1ZX0BvDZ7Ozq7JJMlOuUVZkxzUdTF6ztOdrBFz68mjtC6DqaiuKC6HB30lj6BgZpO50KifS/tu7+M+VdZ8rfeqeb195up+10H+09/ed878LY2aESMePnTUeHA+Fz16wiUZH7gTDE3HOqF2ZM9fX13tjYGHYzzss9/28Xj/zyALv+z7U59Q9Ucs+TOw7xP59KdR3d96nLuHqcL9d81T8wSHt3/1mhciZc+s4Knc6eAa6uXcTnP7g6pwPBzLa7e/3ocl35HJJkopze/kHeON7F6sVlYTdH5qBc6joKUywaYUFpoa7MTqNgCMmaYAB6d0u7gkGyrvloB7c9toPdR9tzsutIwqX/U0KyenEZEUPjDJJ1T+44xMe/9S8c6+jhkVvW8ScfSyoU5LzoiCEkxQVRaipLaTrSFnZTZI5I7zpat2Ih96vrSCZJwRCiuuq4bvMpWZHedXT7h1bzpY+o60gmT8EQomQiznO7jnC6d4B5hbPzak6Z/Z56OXXWUXFBlL+7Zd24p3SKZErBEKI1iTjuqV97/2FZRdjNkRxzuneArzbs5PHGg6xbkZomO5dPnZTZQ8EQorrE0JxJbQoGOS9DXUdNLeo6kuxTMISoprKUwliEJp2ZJOfh6ZcP86dP/ZrigiiPfFpdR5J9CoYQRSNG7eIyDUBLRrr7Ul1Hm186yLqa1AVr6jqS6aBgCFkyEedf9hwLuxkyyzUf7eD27+/g9SPt3PahVXz5I3XqOpJpo2AIWbI6zpM7DnOys1eX5Iesp3+AA8e72Nfawd7WTg6/cxoDCqIRohEjFjUKIhFiUSMWMWLRSOoxeF4QNWLDy0fWKwgeoxEbVc/G2f6Z5c+88tZw19Hf3fIePqip2mWaKRhCNnxvhpZ2rlhZGXJr5j5352h7D3tbO9jX2pn6O5Z6fuhkF4Npc0ouLC3EgP5Bp39gkL5BZyD4m2nvqVnAN2+8XDd2khmhYAjZmkQ5kLppj4Ihe073DrD/2Jkv/X2tHew7lgqCjrRplucVRFmxqJTfXFbBJy5fyqqqUlYuKmNFVSllRWP/8xgc9FRYDA4GoZEKjqHnfYODqbKzHp2+gTPP08uHgyfYTl/aNqviRWx8z3J1HcmMUTCErLq8iPLiGP+8p5VLllaQqChmcbyIAn0JTGhw0DnS1s2+1s7gCODMl//hd06PqLt0/jxWVpXyn9+1lJVVZaysKmVVVRmJ8mIiETuv941EjMKIUaipxmSOUjCEzMx490ULeP61ozz/2tGgDCpLi0hUFFEdL6a6ophEeepvcXkRieB1xbwCzM7vSy0Xdfb0D3f57B369d/ayf5jnZzuO3PnrtLCKCurynhPzQI+VbWclUO//heV6spykfOgYJgFvnPTu9nb2kFLWzctbT0cOdVNS1s3R9q6eetUNy8ffIcTnb1nrVcUi5CoKE4LjyKqy4tTZWlBMp33uz1f/QODdPUN0NUzQGdv//BjZ08/nb0DdPX0097dz4ETncNjAEfauofXjxgsW1DCyqpSrlhZmfryD379L44X5UVQikw3BcMsUFwQ5eILKrj4gvGvfu7pH+BoWw9H2oLQGA6PHlpOdfOrQ+/wk1Pd9PQPnrXuwtJCFsfPHGmcCY+i4QBZWFp41pfq0Jd4Z08/nT0DdPWmPfYOlffT1Xv2l3xXsHz0su6+s9s3lvLiGCuryrhydSWrqspYuaiUVYvLuHBhybj34BWR7FAw5IiiWJTlC0tYvrBk3DruzqnTfRwJgmMoSI60ddNyKvX46uE2jnf2MPqOroXRCFXxIswY/lIfK2TGb1+E0qIYJYVRSgtjlBSlHqviRSNelxTGKC2KDj+mLztTHqO8OKZf/yIhUTDMIWbG/JJC5pcUDp/tNJa+gUGOtvcE4dE9HB5H23owSH3BD3+RR89Pv0cAAASASURBVIe/8MuKzv5iLwnqaLBcZO5QMOShgmiEpfPnsXS+zokXkbPpZ56IiIygYBARkREUDCIiMoKCQURERlAwiIjICBkFg5ldZ2ZNZtZsZneOsbzIzB4Plm8zs5q0ZXcF5U1mdm1a+Xwz22Jmr5vZa2b2vqB8oZn91Mz2BI8Lpr6bIiKSqQmDwcyiwAPA9cBa4EYzWzuq2q3ASXdfDdwH3BusuxbYCFwMXAd8O9gewDeAH7v7GuBS4LWg/E7gBXevBV4IXouIyAzJ5IhhHdDs7vvcvRfYDGwYVWcD8EjwfAuw3lKXrW4ANrt7j7vvB5qBdWZWAVwNPATg7r3u/s4Y23oE+MTkdk1ERCYjkwvclgIH014fAt47Xh137zezU0BlUP5vo9ZdCpwGWoHvmdmlwHbgDnfvBKrd/e2g/hGgeqxGmdkmYFPwssPMmjLYl7EsAnRvzTP0eZyhz2IkfR4jzYXP46KxCsO68jkGvAv4grtvM7NvkOoy+rP0Su7uZjbm7bLc/UHgwak2xMwa3b1+qtuZK/R5nKHPYiR9HiPN5c8jk66kw8DytNfLgrIx65hZDKgAjp9j3UPAIXffFpRvIRUUAC1mtiTY1hLgaKY7IyIiU5dJMLwE1JrZCjMrJDWY3DCqTgNwc/D8BmCru3tQvjE4a2kFUAu86O5HgINmlgzWWQ/sGmNbNwPPTGK/RERkkibsSgrGDG4HngOiwMPuvtPM7gYa3b2B1CDyo2bWDJwgFR4E9Z4g9aXfD9zm7kO33PoC8FgQNvuAW4LyrwFPmNmtwAHg97K0r+OZcnfUHKPP4wx9FiPp8xhpzn4e5qMn5hcRkbymK59FRGQEBYOIiIyQ18Ew0VQf+cLMlpvZz8xsl5ntNLM7wm7TbGBmUTN72cx+FHZbwjbeFDb5yMy+HPw7edXMfmBmxWG3KdvyNhgynOojX/QDf+Lua4ErgNvy+LNIdwdnpmrJd+NNYZNXzGwp8EWg3t0vIXVCzsZwW5V9eRsMZDbVR15w97fdfUfwvJ3UP/ql4bYqXGa2DPiPwHfDbkvYJpjCJh/FgHnBNVslwFshtyfr8jkYxprqI6+/DAGCmXEvB7adu+ac99fAfwcGw27ILLCCM1PYvGxm3zWz0rAbFQZ3Pwx8HXgTeBs45e4/CbdV2ZfPwSCjmFkZ8EPgS+7eFnZ7wmJmvw0cdfftYbdllhiawuY77n450Emeznoc3AZgA6mwvAAoNbObwm1V9uVzMGQy1UfeMLMCUqHwmLs/GXZ7QvZ+4ONm9gapLsYPm9n/DbdJoTrXFDb55iPAfndvdfc+4EngypDblHX5HAyZTPWRF4Ip0h8CXnP3vwq7PWFz97vcfZm715D6/2Kru8+5X4WZmmAKm3zzJnCFmZUE/27WMwcH4sOaXTV04031EXKzwvJ+4PeBX5vZK0HZn7r7syG2SWaX8aawySvBbNBbgB2kzuZ7mTk4NYamxBARkRHyuStJRETGoGAQEZERFAwiIjKCgkFEREZQMIiIyAgKBhERGUHBICIiI/x/ZbpXy3h/+NgAAAAASUVORK5CYII="
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSN Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "\n",
    "test_dataset = UKBB_ROI_Dataset(test_df, pheno_cols_ses2,pheno_cols_ses3, transform=None)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "eid_list, y_test_list, y_pred_list, test_loss1, test_loss2 = test(model, test_dataloader)\n",
    "y_test = np.squeeze(np.vstack(y_test_list))\n",
    "y_pred = np.squeeze(np.vstack(y_pred_list))\n",
    "\n",
    "test_r1 = stats.pearsonr(y_pred[:,0],y_test[:,0])[0]\n",
    "test_r2 = stats.pearsonr(y_pred[:,1],y_test[:,1])[0]\n",
    "\n",
    "test_age_1 = y_test[:,0]\n",
    "test_age_2 = y_test[:,1]\n",
    "\n",
    "test_brainage_1 = y_pred[:,0]\n",
    "test_brainage_2 = y_pred[:,1]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"eid\"] = eid_list\n",
    "df[\"test_age_1\"] = test_age_1\n",
    "df[\"test_age_2\"] = test_age_2\n",
    "df[\"test_brainage_1\"] = test_brainage_1\n",
    "df[\"test_brainage_2\"] = test_brainage_2\n",
    "df[\"test_loss1\"] = test_loss1\n",
    "df[\"test_loss2\"] = test_loss2\n",
    "df[\"test_r1\"] = test_r1\n",
    "df[\"test_r2\"] = test_r2\n",
    "\n",
    "test_loss = 0.5*(df[\"test_loss1\"].mean() + df[\"test_loss2\"].mean())\n",
    "test_mae = 0.5*(np.mean(np.sqrt(df[\"test_loss1\"].values)) + np.mean(np.sqrt(df[\"test_loss2\"].values)))\n",
    "print(f\"test_loss: {test_loss}, test_mae: {test_mae}\")\n",
    "\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test_loss: 6.18095756124604, test_mae: 2.3214909432539432\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           eid  test_age_1  test_age_2  test_brainage_1  test_brainage_2  \\\n",
       "0    [4071544]        66.0   68.000000        64.663628        64.663628   \n",
       "1    [6005293]        61.0   63.000000        65.026764        65.026764   \n",
       "2    [5739520]        61.0   63.000000        64.494644        64.494644   \n",
       "3    [1308382]        51.0   52.999996        64.753036        64.753036   \n",
       "4    [2991501]        58.0   60.000004        64.600952        64.600952   \n",
       "..         ...         ...         ...              ...              ...   \n",
       "953  [3875898]        67.0   69.000000        64.739731        64.739731   \n",
       "954  [4902328]        77.0   79.000000        65.001221        65.001221   \n",
       "955  [2352732]        52.0   55.000000        64.663628        64.663628   \n",
       "956  [3558150]        66.0   68.000000        64.789513        64.789513   \n",
       "957  [1080079]        69.0   72.000000        64.918068        64.918068   \n",
       "\n",
       "     test_loss1  test_loss2   test_r1   test_r2  \n",
       "0      1.336372    3.336372  0.313603  0.308775  \n",
       "1      4.026764    2.026764  0.313603  0.308775  \n",
       "2      3.494644    1.494644  0.313603  0.308775  \n",
       "3     13.753036   11.753040  0.313603  0.308775  \n",
       "4      6.600952    4.600948  0.313603  0.308775  \n",
       "..          ...         ...       ...       ...  \n",
       "953    2.260269    4.260269  0.313603  0.308775  \n",
       "954   11.998779   13.998779  0.313603  0.308775  \n",
       "955   12.663628    9.663628  0.313603  0.308775  \n",
       "956    1.210487    3.210487  0.313603  0.308775  \n",
       "957    4.081932    7.081932  0.313603  0.308775  \n",
       "\n",
       "[958 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>test_age_1</th>\n",
       "      <th>test_age_2</th>\n",
       "      <th>test_brainage_1</th>\n",
       "      <th>test_brainage_2</th>\n",
       "      <th>test_loss1</th>\n",
       "      <th>test_loss2</th>\n",
       "      <th>test_r1</th>\n",
       "      <th>test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4071544]</td>\n",
       "      <td>66.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>64.663628</td>\n",
       "      <td>64.663628</td>\n",
       "      <td>1.336372</td>\n",
       "      <td>3.336372</td>\n",
       "      <td>0.313603</td>\n",
       "      <td>0.308775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[6005293]</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>65.026764</td>\n",
       "      <td>65.026764</td>\n",
       "      <td>4.026764</td>\n",
       "      <td>2.026764</td>\n",
       "      <td>0.313603</td>\n",
       "      <td>0.308775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[5739520]</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>64.494644</td>\n",
       "      <td>64.494644</td>\n",
       "      <td>3.494644</td>\n",
       "      <td>1.494644</td>\n",
       "      <td>0.313603</td>\n",
       "      <td>0.308775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1308382]</td>\n",
       "      <td>51.0</td>\n",
       "      <td>52.999996</td>\n",
       "      <td>64.753036</td>\n",
       "      <td>64.753036</td>\n",
       "      <td>13.753036</td>\n",
       "      <td>11.753040</td>\n",
       "      <td>0.313603</td>\n",
       "      <td>0.308775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2991501]</td>\n",
       "      <td>58.0</td>\n",
       "      <td>60.000004</td>\n",
       "      <td>64.600952</td>\n",
       "      <td>64.600952</td>\n",
       "      <td>6.600952</td>\n",
       "      <td>4.600948</td>\n",
       "      <td>0.313603</td>\n",
       "      <td>0.308775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>[3875898]</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.739731</td>\n",
       "      <td>64.739731</td>\n",
       "      <td>2.260269</td>\n",
       "      <td>4.260269</td>\n",
       "      <td>0.313603</td>\n",
       "      <td>0.308775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>[4902328]</td>\n",
       "      <td>77.0</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>65.001221</td>\n",
       "      <td>65.001221</td>\n",
       "      <td>11.998779</td>\n",
       "      <td>13.998779</td>\n",
       "      <td>0.313603</td>\n",
       "      <td>0.308775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>[2352732]</td>\n",
       "      <td>52.0</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>64.663628</td>\n",
       "      <td>64.663628</td>\n",
       "      <td>12.663628</td>\n",
       "      <td>9.663628</td>\n",
       "      <td>0.313603</td>\n",
       "      <td>0.308775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>[3558150]</td>\n",
       "      <td>66.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>64.789513</td>\n",
       "      <td>64.789513</td>\n",
       "      <td>1.210487</td>\n",
       "      <td>3.210487</td>\n",
       "      <td>0.313603</td>\n",
       "      <td>0.308775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>[1080079]</td>\n",
       "      <td>69.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>64.918068</td>\n",
       "      <td>64.918068</td>\n",
       "      <td>4.081932</td>\n",
       "      <td>7.081932</td>\n",
       "      <td>0.313603</td>\n",
       "      <td>0.308775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958 rows Ã— 9 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple FF Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "\n",
    "test_dataset = UKBB_ROI_Dataset(test_df, pheno_cols_ses2,pheno_cols_ses3, transform=None)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "eid_list, y_test_list, y_pred_list, test_loss1 = test(model, test_dataloader)\n",
    "y_test = np.squeeze(np.vstack(y_test_list))\n",
    "y_pred = np.squeeze(np.vstack(y_pred_list))\n",
    "\n",
    "test_r1 = stats.pearsonr(y_pred,y_test)[0]\n",
    "\n",
    "test_age_1 = y_test\n",
    "\n",
    "test_brainage_1 = y_pred \n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"eid\"] = eid_list\n",
    "df[\"test_age_1\"] = test_age_1\n",
    "df[\"test_brainage_1\"] = test_brainage_1\n",
    "df[\"test_loss1\"] = test_loss1                    \n",
    "df[\"test_r1\"] = test_r1\n",
    "\n",
    "test_loss = df[\"test_loss1\"].mean()\n",
    "test_mae = np.mean(np.sqrt(df[\"test_loss1\"].values))\n",
    "print(f\"test_loss: {test_loss}, test_mae: {test_mae}\")\n",
    "\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'x2'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13845/3299854817.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0meid_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13845/2629268716.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_dataloader, criterion)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mage_at_ses2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mage_at_ses2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Scale age\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m             \u001b[0my_pred_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/green_comp_neuro/green_compute/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x2'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "plt.scatter(df[\"test_age_1\"],df[\"test_brainage_1\"])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f522f7aa7f0>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2df5Bc1ZXfv2eGASQt1o/lx8IYSYZay2VFBsEYscZxAnahBIyZxRgvC1XOOglJauMqr2snK1g2wBYE1vIm8f7jXYzXSwWMQSBmwVBgKjjrmBixIwsh5EAcARIMYOQIsfwQCKSTP/q1eN3zXt9va07fvu/1+VRRaM70dN++771zzz33/BBVheM4jlM9hvo9AMdxHOfgcAXuOI5TUVyBO47jVBRX4I7jOBXFFbjjOE5FOSTmhx155JG6dOnSmB/pOI5TeTZu3PgrVT2qXR5VgS9duhRTU1MxP9JxHKfyiMj2Irm7UBzHcSqKK3DHcZyK4grccRynorgCdxzHqSiuwB3HcSqKK3DHcZyKEjWM0HGqyOSmaax98Gm8uHsPjlswBxOrl2F85Wi/h+U4rsAdpxOTm6Zx+fot2PPuPgDA9O49uHz9FgBwJe70HXehOE4H1j749AHl3WTPu/uw9sGn+zQix3kfV+CO04EXd+/pSu44MXEF7jgdOG7BnK7kjhMTV+CO04GJ1cswZ2S4RTZnZBgTq5f1aUSO8z5+iOk4HWgeVHoUipMirsAdJ8D4ylFX2E6SuAvFcRynorgCdxzHqSiuwB3HcSqKK3DHcZyK4grccRynorgCdxzHqSiuwB3HcSqKK3DHcZyK4grccRynongmpuM4pXgzi7RxBe44TiHezCJ93IXiOE4h3swifdwCd5waYuH68GYW6eMWuOPUjKbrY3r3Hijed31Mbpru6n28mUX6uAJ3nEhMbprGGTc8jA+tuQ9n3PBw1wqVxcr1kWIzi1hzWBXcheI4EYh5IGjl+kitmYUfqs7EFbjjRKCTVWytfI5bMAfTBcr6YFwfMZtZhPz2MeewKrgLxXEiEPNAMLbrw8Ktwfjt/VB1Jq7AHScCMQ8Ex1eO4voLVmB0wRwIgNEFc3D9BSt6YqVaHZgyfns/VJ2Ju1AcJwITq5e1+G+B3lrFsVwfVm4NxrqOPYdVwBW440QgtQNBK4p87Z3kZTB++7rO4WxwBe44kUitu71Fss+wCPapFsq7gbWuU5vDfkMpcBFZAOAmAP8IgAL4MoCnAdwOYCmA5wBcpKqv9mSUjuOYYhWSV6S8O8nLcOv64GAt8G8CeEBVLxSRQwHMBXAFgP+uqjeIyBoAawD8UY/G6TiOIVa+69ES18do4iGLdSEYhSIi8wF8CsB3AEBV96rqbgDnA7g5e9nNAMZ7NUjHcWyxCslLMVtzkGDCCD8EYCeA74rIJhG5SUTmAThGVV/KXvMygGOK/lhELhORKRGZ2rlzp82oHceZFVYheTFDFp2ZiAZ8VSIyBuBRAGeo6gYR+SaAfwDwFVVdkHvdq6q6sNN7jY2N6dTUlMGwHceZDe0+cKBhObvyTRMR2aiqY+1yxgJ/AcALqroh+/lOAKcA+KWIHJu9+bEAXrEarOM4vcUt53oQPMRU1ZdF5HkRWaaqTwP4NICfZ/99CcAN2f//tqcjdRzHFD80rD5sFMpXANyaRaA8A+D30LDe7xCRfwlgO4CLejNEx3EcpwhKgavq4wBm+F/QsMYdJ0mq2JC3imN2+odnYjq1pIq1o6s4Zqe/eDVCp5ZUsSFvFccMeJecfuIWuFNLqlg7uopj9l1Df3EL3KklVawdXcUxV3XXUBdcgTu1pIop3md+5Kiu5ClQxV1DnXAXihOdGJEWVaxu96OniktNlMlTwLL/ZkzqEu3jCtyJSkyfadUSVapozVaxS06d/PbuQnGiUkWfaawoiyr6wKuYkl/Fe7AMt8CdqFTNyoxprVlaszFdBKntdELfvWr3YCfcAneiUjUrM6a1Nr5yFJ8/dfRAO7JhEXz+1O6Vo1Wn+CrCfPeq3YOdcAXuRIWNDkklOSSmtTa5aRp3bZw+0I5snyru2jjd9XdnF51U5thyPMx3r2KEUhmuwJ2oMD7TlCzImNaalbXPLDopzbHleJjvXkW/fRnuA3cApOUzZfo1xhpvzCgLK2ufCe2z6okJ2FwLq/EsmDuCV996t1CeJzW//cHiCtxJLqwqpMjY8Voolpjx5FYx1cyiY7VYWN07VuMpazAWaDxWWVyBO6bWmAUhRcZa6FaLUixrzcraZxYdq8XC6t5hxxNalF/bM9P67iSvOq7AneTCqkKKrOhBb5entigxWFr7oUVnYvUyfO32x7E/JxvK5HliheQxixezKFc1M/RgcQXuJHfThxTZsMiBSI08zfA7IL1FCeBcOrGs/antu1qUNwDsz+T5XczEus14d39jrqd378HEus0HxgnY3TvM4sUsylXMDJ0NrsCdJG/6ToqsSHm3y1NblFI7Z7htw/Ol8mvHVwAArr5n6wHl3eTd/Yqr79naE4UZWrzYCBOgWjVwZoMr8AEgZPlV7aYfLVHOoznlHHtRCs1xai4dZhHcXeI3zsvHV45iavsu3LbheexTPejkIwZ2Ua5LhAmDK/Caw1p+VbrpGeUcc1Fi5jg1lw7jhmIoSz4aW7LIfK7P/MhRuOXRHYXyQcUVeM1JzfKzgFXOsRYlZo6toiysuHjV8YXK8OJVxx/498KSmOqFuZjqmPdXFcvt9hpX4DUnNcvPipR2DMwcW0VZWNH0c+ddHxevOv6AHACuOm85Ju7cjHf3vW+pjwwLrjpv+YGfmYggwGZhYj9rkHAFXnNSO8xLDQvFwszx+MpRrJvagUe27TogO2Xx/L76ya8dX9GisNthdjpDAuwvcKcP5TwxTDQLg5Xbp064Aq85KUaYpIKVxcvM8ZWTW1qUNwA8sm0XrpzcckCJxt4tWYQ1FinvdjkTzcLAHLwOGq7Aa07MKIGqwVq8FlE8TNheTD/55KbpFvfI9O49mLize6uYgYlmYWCij4DGYtnJNVQnvBphzbEqUVpHYlbtY6xHpsyp1XiuuXdri28bAN7dp7jm3q0tspRKzjLzc+XkFtzy6I6W+/2WR3fgysktUccaC1fgNadO7aOsYUrFMvM3uWkaX7vj8Ral+rU7Hu9a2TFlTq1qfRdFl7TLrRaLuSPFaqZMXgYzP512OnXEXSg1h/Wr1qVLdzcwvmsm8uGK9U/M8AXv14a8OYcCoMgG7/b4jRlPc0Fpjqm5oADduUesDlUPGxnGW++2J+435N0S8skPmp/cLfCaw1iZqRX3jwXTwqwswiEvL1JO7fIy9ZGXM9eBGU+nBaXJgjmt9bGL5Mziv3Bu8fvk5btLrP0yeSdCO4uyBbGucSquwGsO4ze0dLOk5DMNjYU5H4hp0THXgRkPs6Bc/bnlMx7+oUzepL0JQpH8qvOWY2S4VT22x4oz7wNw1yu0wM09tNiqL5NXHVfgNYfxG1oX9w9Z8jGUPDMWRmG2RzgUycvCkLsNT2auAzMeluE2xdv+M9McYXzlKNZeeFLL/bX2wpNa7q+32+a4SG51vd7cW/xZZfKq4z7wASDkN4xZ3N+qm45F8SirDMpPnLBoRox3U96ECYFjrsPE6mWF2ZHdxvWvffDpwiiU/PywzRFC99eekh1BXm51vQYt2cct8D6RkqvBqks384CxUR2drLFmDHP+9xN3bm6ZQ2YszPkAs4N57v8Vf1ZezsxxWVGmdnmR4u0Wq/kBbO5lZjyMKya1Q8xeP+euwHPEUqqpHRoySoqBeeAtlDwTw8yMhV24xleO4pE1Z+HZG87FI2vOmjEvVp3QmWJNl+cOIvOUycuYX3KImZdPrF6GkaE2//aQdB2Xzhx0MsqZccVYuphmS4zn3F0oGTELCaXWERywKQ7FuBsYN0FIITIxzDFLzlrVqWYWAsYdwfDW3vcoeVHXnjzMvcwUxWL87cx3Z0tHxAibjVHbhrLAReQ5EdkiIo+LyFQmO0lEfprJ7xWRD5iMqE/ETHiJfWgYC8bKZKxedus+27GwXDm5BSdefj+WrrkPJ15+/4ysPtaSD+3wLL43y94St0tefs29W7GvLR5x3/7WnQ4Tl84cdFo1I2aue6znJkZtm24s8DNV9Ve5n28C8Ieq+nci8mUAEwD+xGxkkYlZSCi1juCWhKxMxuoNWVEL5owU1tFoj20OjYXZdTVTs5s0U7OB90uyMpUGmc9iDiiZ6n8jQ0CRsdpl4iO102EPDUPXYkFJ7fG8C4WpT858VqznJkYl0Nn4wD8M4MfZvx8C8PnZD6d/xLR+Yh4aWmJ1RhDyKYesqKs/t7zQN5uPYWbGy+y6mNTsTpUGu/ksANjXZhm3//y7qxYXjicvL/OmdOlloWAPDUPXgnGhXHXecgy3XffhoVZXDEOs58bqOe8Ea4ErgB+KiAL4K1W9EcBWAOcDmATwBQDHF/2hiFwG4DIAWLy4+OZLgZhlV2P7Xi2qs8VuytvJimLmz6rNGaOgmEqDzGddfc/WQp9zvuzq2JJFuO2x51tcG8NDgrEli2DNnJGhQr/znJwpz4RHMpUP2YqFQwD2tf3cTsi/HatGfoy2fqwC/6SqTovI0QAeEpGnAHwZwF+IyJ8AuAfA3qI/zJT9jQAwNjaWbEGC2GVXYx0aMi4ABqvSq1ZYbJOZB5mpYcIoecZFwCixtQ8+XeiX7nb7z7gjDh8ZLlTgh+esSqZPZaeooeaYGVfM2gefLqwr3m2eQczemr3uHEW5UFR1Ovv/KwDuBnCaqj6lqmer6qkAbgOwrWejjEAVy64ytTysqrPFLL3KENqSM4drzBaXSc1mMjHfKQmBK5OXwVyHQ4eLB5SXMyF5jA+cCX1k3odZBJlryriq6tRbM6jARWSeiBzR/DeAswE8mVnjEJEhAFcC+MteDrTXVLHsqmUtD4sICatSp0DnyA+rok/MAvhWSQp2Xj7nkOLHKC9n6pMwMNdh3mHFG+u83Coc0apPJVOEirmmzAJXpz6xjAV+DICfiMhmAI8BuE9VHwBwsYj8HwBPAXgRwHd7N8zeU8UDQUZhMjc9oxAZa5UtdRr6rFBRfquiT8wCyChMK+XMJLww2ZqMxWuFVfU/plojc02Z6xUzYKHXBBW4qj6jqidl/y1X1esy+TdV9cPZf2tUq11wN+ZFtXI1MIvOxasKz5Zb5IxCZOJrmcXCIvLDqugTM5aJ1csKIx/yCxfzveeUxPDl5Uf+2qGFr8nLme0/49I5rGTXkJcz34tRvFbFvphryixwMaJDYuGp9BkTq5cVlsXsxUW1ctcwi8614ytw6emLW9wEl56+uOUA02r3wVhIFpEfzPde+uvFr8nLmbFMbd9VeGg4tf39sEHmezOW6i9eebPwNXk5M2YmJG/ve8W7g7ycWfwZmPEwuw9G8TILnGWSV7/xVPo87Tdaj/YUVl1y2NDHa8dXdIw4YaIxmNN9JpLAIoSL+d6PPvNq4d/m5cxYbi2IVmjKm3PKRHRYuVnmlyQxldU2KYOxnJvfr1MIKvPdmVBDJt2eiRRjn61eR4fEwi3wjE4hStZYdcmxsiSYbaeV39li+8ocPlqNhVF0b7xd7Fsuk8+Gve8VH6qWyctgfdfXjq/AtuvPwXM3nItt158zwxBgkmuY+4tJt2fOLKyaR1QFt8AzYh5iMhYkG3dtYUms3/hCqbybRBTGArdIbpjcNN1IZsk9yLc99jzGlizq6n2sYv+ZzEc2DTyElSU/JEBROZShbk8fEU6uYcP2LGL7GXdN7KS0XuIWeEbMQ0zGguzGzTJbS4JRCsz8sCGLoVT6EH9895ZCv/Qf372l5C+Kmdw0jdv/vnUhuP3vn2+Zw3klceBl8jKY1mMxKSsh3i5nyhGEdq5WoYbMM8EUxapiyHAZrsAzLE+mLXoxptaMmJmfWLWYmbZZzFiYuuLX/faKGW4FyeRNyqzWvHx85ShOW7qw5fenLV3YE4uPaVjMwNxfVsqZwSpEcNDiwAcC1p8cKi3KdIthLAArvzQDE+bFloq1iOSxiC1mFhwmXnpq+67Cs+18FApTYIopeGXF6yW+97ycWXSY+4t5HyuYaxqrXHEquALPEdrahxJMAM6qY6wWxm/IWhKhReeSEgXULp/avgsvv/Y2FMDLr73dosSahKrpMYTS1xkFz7ipGG7dUBKFUiIvw6qkAQPjHvmtE4qLX+XlzP1VVNq2k3w2MEYEc909DnxAYR5mtoZyEd2mBDMn7syiM7Zk0QyLaUjQUuGOeZ9O1fS6IZS+/okTi5VPXm5V24Y5FGOUc2q9Gn/+0utBOdN2LTYhI4u57laLewq4Au8C5mFmsEoJZgokMcrlmnu3zrCY9itadg3M+7AlQUOEFiamiXDMgyrmejKLtlVaOgNjaDCutZhjZmCbZletcF0ZrsBzWER0MAdIzMPMNJRlokcY5WJVLc6K0ELJuKCsDqqYyn4Mp5+wMChnYs5jsrvkvsjLLcccq7u9R6FUECYyxCKi47MnHRuU08qwKPyhS5jFwup95pbU+yiTl2FhyTM7GOYArj1JJSQvg3FZxIQxNJg5ZKJ9rAqqMXgUSg1hbg6rVfm+J14KytlCS0WHofnxMA+hVT0L5n0OGyk+fCyT9xImioc5yLMqu2pVIdAqRJAxNJhdIFPsy6qgGgMTCeVRKBWDuTmsVmXmQWUeDGY8y487ovA1eTlTzIopJDS2ZFHhg5o/6IxZxjREp+zSJowvPTWYfqCMX/oHm4sNjRnywC6QKfYVs6AagGBNI+b5qwoDocCZmyP6qhx4MJgIE6ZgExCuZ3Hux4qtsby8UyuvbolRh4I5H4iZhMIoVSbrc3zlKNZ+oa1myBdaa4Ywfmm2fVtoF8iGR44tWYTfmH84BMBvzD98Rg9PtoZJCLamUbu7sl/RQLNlIGqhMFXnmPokQ1Ic35pfzJkeip0ejOaDyLS8sjpYZGLOrZQd0+A2NM+/efS8wtKrv3n0vK7GEhNGqbKFqmJV0rNq+jy5aRoT6zYfUKzTu/dgYl3rNbeK8KKbRxdEXeWbR1eFgbDAmcB9JkmAybhjHlTmJmN8r2wIVyiRh1HOVoehTKJTyDf91t4S67pE3msOKTnQLJOXwRTFAsLXkzmcZdxmVgfBV9+ztdAqzucHMDVMGJgxW4W7psBAKHCrsqtjSxbNmLAhYMZ2MITVdpFpuMsk4DDxvlbWPuMn3/picWRGU55aFMF7JWmHZfLZwFzPsgjHvJwJj2SaYjCdfRiFaeXCrFOWJcNAKHCAy+BiIlWKMg27jQyx6lDCFHVifJTMeGIVqgLCD3zM8wrmOsSEuZ6MJf/L1/cWviYvZ85Y3i75sDJ5GVaKlzHWUrums2FgFHgIJlKFcTUwUQLMdpE5WGTcGlaWs9XJvUUYHBMqZhVux1yHmMRMqLLKGGarNcZKb0+ttO9scAWewTYsKKK9YUEoSoC56ZkwL6sUbrqinEFiERN/TFlIgVCx/ILJyMtgmxHEImb1P+azmIWdKXjF1GZvvm62CXlM95+q4Ao8w7JhQQgmyYTxGzJhZ0wSBfOAMSFlDIxC/OixxfHtTTkTKnb9/T8vfI8yeRnMrqvsIcrLmR1BzNojxxxxaFDO+NILP7w9JJb47szhtmVC3mybiqSCK/AMRqkyFglTD9zKqgtV7QO4JAqr6ogMjEIM+V6Z92B8vFYwirddqRTJmbMItpNOiHfeK/6DvJzxpTMLOzM/zOG2lZsTqE9PTFfgGYxSZSxVxpJglCFzus8WEgolUTA7i5ilRWP5eeeU1Ggpk5fBKNV33ivWhmXyXmMVSsfcy0xRLKvPill3JQUGRoGHVlyrRBXGkmDcNXtLHuy8nL1ZJ9a17QjWte4ImAgTxoqywirmPMT1F3ysK3kKpFa+lbmXmbBZZjG1cnN6NcKKway4sZQGwIVMMdY1U6KUSaKYWL2ssKFDfjxWVhQD872sKIpG6AVWiveS00u6J5XIZwN7iBm6l5ms4sNLCp7l5VZ9WVPLI5gNA6HAmRU3ZngWE6vKLChMMSZmqzy1fVdhanG+IBFjRZV5Hrr0SEQrMmV1MFuWwp+XWyle5kzDCsZlyNzLTFYxs3Nl+7IOUk/MgaiFQrUnmzNSqOy6jRtm6qUA4XoWF686Hrc8OrOFWz56xMrt0yk5pKkYGCuKTQUPEctCspq/X71RfDCal187vgLP7nyjpbHxGScuOijFe+34ip4o7HZGS2oItVu5FrVZhkUKjaV2Qyb0Wc3frX3waby4ew+OWzAHE6uXzVDyobpHVWEgFDhTzMrKx8s2eZ3cNN3xJhtbsgjfe3RHS+Zne9o+c9PPO3S4MGMzH2rI7D6s6mIzxb6Y62WBSHHkR7fXnLEeJzdN42c7Xmv5/c92vIbJTdNdK7/QvWNFTEVnuQO2UPJVYSAUOHMjWvl4GaXAVGfrlLbffA1z0+8veU2ZvNccMlRskeeDbs78yFGFu4+yUM+DxaoCHkMnN143ioOp5sjALP5Wim7OyFDhQp8/oGStfStiVXTsNQPhA2fSdBkfL5MhyCgF5mDRqkKgleVsBeNmCYV0phaJwWDlrmHCVBnYTk0WCS9WB5TOTAbCAp/cNI3bH2tL033seYwtWdRVPeKrzlveYv0AB1dDgTlYZCykmAevC+eOFLoK8osX4x5hCCk7Nv49hNW5hxWMu8uq61HTh37bhsZzMSyCi1cdP8O3fuXkluBrQjC7W9baj+U+qgoDYYFb1SMeXzmKL378+BZL/osfP74nlc6s6pxYUbZIdbt4MfMTq96HVb0UK0aGix/HMnkZbCGvZ3e+0WLUPLvzjZbfM6VrGdioD4uKoYNG8grcIuWVsXgZF8rkpml8b0PrDf29DTtaxhSzel1MCzwfUlgmZyxjZn7Yg+DZwnynmDD36dySmMy8nCkYdsm3f9oSEQMAj2zbhUu+/dMDP99acA5RJA89o0yZCoY6JeBYQSlwEXlORLaIyOMiMpXJThaRR5syETnNenAxV1zGhXLF+icK46WvWP/EgZ9jVq+zKpnKwPY+DJFSdb+ig9JO8tnAlEZgfPuHHlLsT87LmTluV95FcmZBZp5Rq2tepwQcK7qxwM9U1ZNVdSz7+esArlHVkwH8x+xnU6xWXGbbzrhQUmuUy/ZQtICx9hkFFHN+UqL9gK5IzihM5j6NqeiYZ9RqPHVKwLFiNi4UBfCB7N/zAbw4++G0YnXhmQLuMW8Opkwnk9XILCgMVlEdVoeLIZh2YKlhVTzKqmYIA3NfMM+ot0vrHawCVwA/FJGNInJZJvsqgLUi8jyAbwC43HpwVheeKeDO3BxWyT5M9bqyInW9KF73iROLe3qWyctg6pMzhBavvSUTWCZPAebeYXaKe0pugLzcyufMLMjMM8p0UALCvnSr3rZ1gg0j/KSqTovI0QAeEpGnAFwI4A9U9S4RuQjAdwB8pv0PM4V/GQAsXtxd3QfLTDAmO2vd1I4WH+Api+e3/M0lqxYX+kcvKelWPxuYbEQmtI8h1ESYhalPzhBr8Tp0WAqVfi8seaswVeZ9OnVz6iYEkAllpZ/RQAelpi+9+T5NXzrQmqBklYBTl3BEygJX1ens/68AuBvAaQC+BGB99pJ1mazob29U1TFVHTvqqO4sgJgr7pWTWwpP5fMhUzELCTFW1FXnLcdwW2zd8FBv4tKZ6AcrF0osd1ZqljyzU2RCLK3cNcy5B/OMMh2UYkaY1CkcMWiBi8g8AEOq+nr277MB/CkaPu9/AuB/ADgLwC96McBYKa9MQScgXiEh1ooaApC/7fsZF8oWJAoRK5WegUkDZ2CTnEL3+2GHFI+nLMplNlgVmGIOrlM5eK2aFc5c9WMA/ERENgN4DMB9qvoAgH8N4M8z+X9C5iapKmxMdchPx9QjZmCsKMaysYI5MD3hqLmFrymTl7F+4wtdyXsJkwbOYLU7ebvkOuTljC+deU3MPAN212WRF1KncMSgAlfVZ1T1pOy/5ap6XSb/iaqemslXqerG3g+3d9DdbQL9Lq0OkBhSuxG37XyzK3kZFtE1l5bU2c7LmYgOqyJn7MIeUlCMomOirq46b3lhE4/8a6yMEQYmiMDK9VGncMTkMzFjwXSBYQoJMUkLVqnizI0Ys/BTrAxKJoGJOa9grGtmjpnFn1nYGQU1sXrZjId2CK3dkxhfOoDC85M8VmF7zPywvnQLP3mdwhFdgWcwXWCYQkKMVfy7JVErZfIyGKUQswVXLJhUcaChxLddfw6eu+FcbLv+nBlnF8z1ZB52xtXALOyMgpravquwzHC36f9MNyKrIAKryodWO846hSMORDVCBqubY0FJaF++psrYkkWFh3T5Zg1MiCCjFKw6wVgdUFpglZptVRObqWXN3F/MYR9z2M6E5LH3u0UQAVv5MIRlow+vB14zrNwRTJxuWe3mvJzxYzIPYadOME2YEEHWirIg5Htl0/FD/mT2kC5kGVr1YWSSfay6rsf2A4d2Qwx1cn1Y4Qo8w6pTPFOrgm3gGipdyzyEzMPMNH0YW7Ko8NArv2uwIuTnpQ+c17UdOK9rPXC2OqRjm+2GshGZxZ/57szCPrF6GUbaLujI0MzsyJSok+vDCnehZDBbZWbLbbXNm9w0jbs2TreUrr1r43RLEwomC455mOeXNDaYnzsUXPvg04WVGLuNnR0paamW3wR08vOOrxylrNBONeCb47WMN6e25IFsRAam2TV9D7avBemWkjlAXVwfVrgFniO0VWYUh9U2j7GcGYuEsdLffKd4R5CXMwsBE5b3a4cXR5Dk5bduKKlDnckZy5mJo49Z2tYqZv/a8RU4o61GTfuZBnMPMoeYTvq4Au8CNhwq1H+T8Tmzh0xT23fh5dfehgJ4+bW3Z0QjMA8z06dyfknoXl7OuGKYuOqQK8Eq1j5mHD3jt2fOWJgzDWZhTy2HwDk43IWSI1TghrHAGdfHYSPDhUkph7XFH4e2wc2WV/lxNH9uWmRWncWZAzbGxcS4a0IwZQaYKB7LqIbQvcPMDXPGwqaBh1wNlt/d6R8DY4FfObkFJ15+P5auuQ8nXn7/jL5+TBIFs3VnXB+MFcpYzmyXHIvO4syYqaYPBiV5GfcIE/fqytwAAA2JSURBVMVj5e5i7h1mbpj7y8pyTjGiwyJNftAYCAXONGdlFC+zdWe2yow7gnHFpFargnExWaWmh2CyEa2iGph7h1HOzP1lWSM/pYiOOlUIjMlAuFCY5AfGsmEOvZitMmOFMq4YK0SK/c758TARL8yCYrF1Z+ugMxELFlENzKLNzB9zf7GRM0y965QiOupUITAmA2GBs4qliOO63L4yn8VYoTHrIzPxx4zFxljgFlt3xj3CwmzbQ6+xqvVhZUTEtma9QmD/GAgL3KqzCGM9MmnVzPtY3tBW3UdCFhvbAGBq+66WtOp21xAzDmD2B7NMyjnzGitXFnNfMNZ+TGuW7aQTgt2Z1aWTjhUDYYEzaeBsNl3IemQy7pj3WVBSrzkvZ6oaMtYYUxu6+V6dLC2mJ2aZa6jb8VgczDK7HCv/NnMdGB+4VSamFTErBLqffCYDocDZNPCQUmAPfva1JUi0/8y8D+PWYMq3Mg/YR489ovB98nLm4XmzpPdlXs6Mx9JF0glG0bFp6UziTOh7M+4RK3egFTErBMZ0K1aFgXChWKWBA2E3wtX3bC1MA8+ncDMwNVWsquD9r23FpUjzcqttOTOeogbTpy1daL5VZrbtTNw649KxWiyYa27ZDDxEzAqB7iefyUBY4DEvPBOjzFizjBXFFPdn3odJIGErAIZgXENMg2kLGMuZjVsP7d6Y68C8hnGzxAwRjBlPXqdOOlYMhAJP7cIzW0HmwWCK+8fsqsLAuIaYBCWLyAdG0VnFrbPnJ6HXsPVbLM4IGOq6WFSFgXChxNxSMrBuhFC0BhPfbhWxYRVpwbiGQp9lFfnQfH2MlHPmOli5YmITK57c6l6uEwOhwFO78IxSYBJ5umlI0Om7zhkZKixEla8iaNWRh/nugmK3TvOTYobJsYu/VeKM1zDpTErJRykwEC4UIN6WkgmBs4paYN0aIXfD9Rd8rNCXfv0FHzvwM7NYMM2GLRpnxLRCGRdBzPA2dyM4eQbCAo/JVectx8Sdm1tqLbeHwFltlZni/oy7ochdc/Gq1u4/TPQDc+BnsRuKbYWGrL6YO4LUdpNOf3EFbgz7gFlslZlmsYxyser+wx74hb57yF1TxTMNS9yN4DRxBd4lV05uCXbXtnjAWCV17fiKjg1irVKvmYXJyjIO7SxiW6Eh//ag+6Wd/uEKvAuYBgpWWCkp5vCRtSBDC5PVgR+zs4hlhTIuqNR2BM7g4Aq8C5iwPUsslFSsEq8At+iwIYChnUUsrHYnjtMLXIF3gWUDhVhV1awqMbKkdOBnQYpx147TxBV4DwgpZ8tElBBsiVcgbEEyi07oNVVTiGzMfqzr6Th5XIEbwzzMMa1QJvyvObZOn21VO7tqB37M7qRquwqnPgxMIo8FTKIKk4AT0wq1Svywqp1dtUQUJpGnarsKpz64Bd4FTKIK8zDHtEKZmioMVuVQq3jg5+ntTqq4Au+Coka67XLmYY4ZdsY2R7aIdWYVWd0SUVIMI/TWY4OBu1C6wKppb8wSnIxbg6nlYVUOtY7EvJ4M3npscHALvAssIzpiWaGMW8Mq1rmK7hErUtpV+KHq4EApcBF5DsDrAPYBeE9Vx0TkdgBN02oBgN2qenJPRpkIVhEdMWHcGlaZmOxrnN7ih6qDQzculDNV9WRVHQMAVf1i9vPJAO4CsL4nI0wISxcB01HGousMM+bUOhY5s8Ov5+Awax+4iAiAiwDcNvvhpI2Vr5PxUVr5MZkxp+i7tli8BpUUr6fTG0SJNHAReRbAq2jU1P8rVb0x97tPAfjPTcu84G8vA3AZACxevPjU7du3W4y70pxxw8OlrphH1pxFv8aSlKIW2hOCgIYC6ufBYNVI6Xo6s0dENhbpWPYQ85OqOi0iRwN4SESeUtUfZ7+7GB2s70zZ3wgAY2Nj3RcNqSFWMdWWpOS79kO42ZPS9XR6B6XAVXU6+/8rInI3gNMA/FhEDgFwAYBTezfE+mEZU11HmMXLLUzHIXzgIjJPRI5o/hvA2QCezH79GQBPqeoLvRti9Qj5by1jquvoKw4dwnmcs+M0YA4xjwHwExHZDOAxAPep6gPZ734HA3B42Q2McmEOFi2b6VZNyYcWLyY5yXEGgaALRVWfAXBSye/+hfWAqo6l/9aitnYVS52GEoI8ztlxGngmpjGs/9ZCqVplWaZIp8VrkM8HHCeP10IxhkmisHIBMJ9VR2vV45wdp4ErcGMY5WKlVAc1yzK14lGO0y/chWIMU387ZhPhFEudWuBxzo7jCtwcpv52zCbCg1wh0HHqjitwY6xKs1ri1qrj1BNX4MZYlmZ1HMfphB9iGlPHQ0PHcdLEFbgxg5wC7zhOXNyFYgzj365idqTjOOnhCrwHWKTAO47jhHAXSh+oY3ak4zjxcQXeB/yg03EcC1yB9wGv5eE4jgXuA+8Dnh3pOI4FrsD7hCfyOI4zW9yF4jiOU1HcAk8Yb9zrOE4nXIEniif7OI4Twl0oieKNex3HCeEKPFE82cdxnBCuwBPFk30cxwnhCjxRPNnHcZwQfoiZKJ7s4zhOCFfgCePJPo7jdMJdKI7jOBXFLfABwBOCHKeeuAKvOZ4Q5Dj1xV0oNccTghynvrgCrzmeEOQ49cUVeM3xhCDHqS+uwGuOJwQ5Tn3xQ8ya4wlBjlNfXIEPAJ4Q5Dj1xF0ojuM4FYVS4CLynIhsEZHHRWQqJ/+KiDwlIltF5Ou9G6bjOI7TTjculDNV9VfNH0TkTADnAzhJVd8RkaPNR+c4juOUMhsXyr8DcIOqvgMAqvqKzZAcx3EcBlaBK4AfishGEbksk30YwD8WkQ0i8nci8vGiPxSRy0RkSkSmdu7caTFmx3EcB7wL5ZOqOp25SR4Skaeyv10E4HQAHwdwh4icoKqa/0NVvRHAjQAwNjamcBzHcUyQNn0b/gORqwG8AeAzAP5MVX+UybcBOF1VS81sEdkJYHvBr44E8KsCecr4mONQtTFXbbyAjzkGsx3vElU9ql0YtMBFZB6AIVV9Pfv32QD+FA0lfiaAH4nIhwEcGhpg0QCyz5hS1bHwd0gHH3Mcqjbmqo0X8DHHoFfjZVwoxwC4W0Sar/+eqj4gIocC+GsReRLAXgBfanefOI7jOL0jqMBV9RkAJxXI9wK4tBeDchzHccKkkol5Y78HcBD4mONQtTFXbbyAjzkGPRlv14eYjuM4ThqkYoE7juM4XeIK3HEcp6L0RYGLyLCIbBKRH2Q//42IPJsVy3pcRE7ux7g6UVTQS0QWichDIvKL7P8L+z3OJiXjvVpEpnPzfE6/x5lHRBaIyJ1ZgbT/LSK/lfIcA6VjTnKeRWRZbkyPi8g/iMhXU57jDmNOco6biMgfZEX+nhSR20TkcBH5UJa5/n9F5PYskm92n9MPH7iIfA3AGIAPqOpnReRvAPxAVe+MPhgSEXkOwFhbQa+vA9ilqjeIyBoAC1X1j/o1xjwl470awBuq+o1+jasTInIzgP+pqjdlN/dcAFcg0TkGSsf8VSQ8z0DDiAIwDWAVgN9HwnPcpG3Mv4dE51hERgH8BMBHVXWPiNwB4H4A5wBYr6rfF5G/BLBZVb81m8+KboGLyAcBnAvgptif3QPOB3Bz9u+bAYz3cSyVRkTmA/gUgO8AjTBVVd2NhOe4w5irwKcBbFPV7Uh4jtvIjzl1DgEwR0QOQWNRfwnAWQCaRqrJPPfDhfJfAfwHAPvb5NeJyBMi8l9E5LA+jCtEUUGvY1T1pezfL6OR9JQKReMFgH+fzfNfp7RVBvAhADsBfDdzr92UZf6mPMdlYwbSnecmvwPgtuzfKc9xnvyYgUTnWFWnAXwDwA40FPdrADYC2K2q72UvewHArNtkRVXgIvJZAK+o6sa2X10O4CNoFMVaBCC57RsaBb1OAfDPAfy+iHwq/8ssCzWlmMyi8X4LwIkATkbjxvrzPo6vnUMAnALgW6q6EsCbANbkX5DgHJeNOeV5Rubq+RyAde2/S3COARSOOdk5zhaT89FY4I8DMA/AP+vFZ8W2wM8A8LnMP/t9AGeJyC2q+pI2eAfAdwGcFnlcQbJVtVn3/G40xvhLETkWALL/J1MTvWi8qvpLVd2nqvsBfBtpzfMLAF5Q1Q3Zz3eioRyTnWOUjDnxeQYai/rPVPWX2c8pz3GTljEnPsefAfCsqu5U1XcBrEdD9y3IXCoA8EE0/PmzIqoCV9XLVfWDqroUje3Qw6p6ae7mETT8Qk/GHFcIEZknIkc0/41GQa8nAdwD4EvZy74E4G/7M8JWysbbnOeM30ZC86yqLwN4XkSWZaJPA/g5Ep1joHzMKc9zxsVodUUkO8c5Wsac+BzvAHC6iMzNdFrzXv4RgAuz15jMc98yMUXknwL4wywK5WEARwEQAI8D+Leq+kZfBlaAiJyAhhULvF/Q6zoR+XUAdwBYjEaZ3ItUdVefhnmADuP9b2hsORXAcwD+Tc732XekET56ExqVLZ9BI9JgCAnOcZOSMf8FEp3nbEHfAeAEVX0tkyV5HzcpGXPq9/I1AL4I4D0AmwD8KzR83t9Hw028CcClzY5mB/05nkrvOI5TTTwT03Ecp6K4Anccx6korsAdx3Eqiitwx3GciuIK3HEcp6K4Anccx6korsAdx3Eqyv8HdcLx8JqL1icAAAAASUVORK5CYII="
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('green_compute': venv)"
  },
  "interpreter": {
   "hash": "96e4927380308772faf387ce1ad6de9eaed4a7d7aadcf2622a8269a7d5f191c8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}