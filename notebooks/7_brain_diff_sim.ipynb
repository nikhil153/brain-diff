{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## LSN theoratical toy example\n",
    "### Quadratic brain ROI trajectories with age\n",
    "\n",
    "### 1. Additive initial factor: subject variability\n",
    "### 2. Additive time shift: ROI variability\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.simul import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    map_location=lambda storage, loc: storage.cuda()\n",
    "else:\n",
    "    map_location='cpu'\n",
    "                    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Brain trajectories\n",
    "### ROI variability: Additive time shift: ROI variability\n",
    "### Cortical thickness trajectories can start: 2mm, peak: 3mm, thin: 2.5 ([over lifespan](https://pubmed.ncbi.nlm.nih.gov/24948804/))\n",
    "### Individual differences (std) ~ 0.1mm with smoothing ([source](https://www.pnas.org/content/pnas/97/20/11050.full.pdf))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_timepoints = 100\n",
    "t = np.arange(n_timepoints)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2,ncols=2, figsize=(15,10), sharey=False, sharex=False)\n",
    "\n",
    "func_type_list = [\"exp\", \"poly\"]\n",
    "func_param_list = [\"roi_init\", \"roi_time\"]\n",
    "\n",
    "for f, func_type in enumerate(func_type_list):\n",
    "    for g, func_param in enumerate(func_param_list):\n",
    "        if func_type == \"exp\":\n",
    "            if func_param == \"roi_init\":\n",
    "                func_params1 = {\"init_val\": 1, \"decay\": 50}\n",
    "                func_params2 = {\"init_val\": 10, \"decay\": 50}\n",
    "            else:\n",
    "                func_params1 = {\"init_val\": 10, \"decay\": 10}\n",
    "                func_params2 = {\"init_val\": 10, \"decay\": 80}\n",
    "\n",
    "        else:\n",
    "            if func_param == \"roi_init\":\n",
    "                func_params1 = {\"init_val\": 1, \"peak_val\": 10, \"time_shift\": 65, \"poly_order\": 2}\n",
    "                func_params2 = {\"init_val\": 9, \"peak_val\": 10, \"time_shift\": 65, \"poly_order\": 2}\n",
    "            else:\n",
    "                func_params1 = {\"init_val\": 1, \"peak_val\": 10, \"time_shift\": 50, \"poly_order\": 2}\n",
    "                func_params2 = {\"init_val\": 1, \"peak_val\": 10, \"time_shift\": 80, \"poly_order\": 2}\n",
    "\n",
    "        traj1 = get_brain_trajectory(n_timepoints,func_type, func_params1)\n",
    "        traj2 = get_brain_trajectory(n_timepoints,func_type, func_params2)\n",
    "\n",
    "        ax = axes[f,g]\n",
    "        ax.plot(t,traj1, label=\"roi-1\")\n",
    "        ax.plot(t,traj2, label=\"roi-2\")\n",
    "        ax.set_xlabel(\"age\")\n",
    "        ax.set_ylabel(\"thickness\")\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        ax.set_title(f\"traj_type:{func_type}, roi_variation: {func_param}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate subject-specific random samples \n",
    "### Additive initial factor: subject variability"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# same init factor for each ROI\n",
    "n_samples = 10\n",
    "intersubject_std = 0.5\n",
    "\n",
    "roi_1 = get_traj_samples(traj1, n_samples, intersubject_std)\n",
    "roi_2 = get_traj_samples(traj2, n_samples, intersubject_std)\n",
    "\n",
    "palette = 'husl'\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,5),sharex=True,sharey=True)\n",
    "with sns.axes_style(\"whitegrid\"):    \n",
    "    ax = axes[0]\n",
    "    g = sns.heatmap(roi_1, ax=ax)\n",
    "    g.set_xlabel(\"age\")\n",
    "    g.set_ylabel(\"sample id\")\n",
    "    g.set_title(\"ROI-1\")\n",
    "    ax = axes[1]\n",
    "    g = sns.heatmap(roi_2, ax=ax)\n",
    "    g.set_title(\"ROI-2\")\n",
    "    g.set_xlabel(\"age\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract cross-sectional samples\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "roi_list = [roi_1,roi_2]\n",
    "y_baseline, X_baseline, X_followup = get_cross_sectional_samples(roi_list, followup_interval=10)\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,5),sharex=False,sharey=False)\n",
    "with sns.axes_style(\"whitegrid\"):    \n",
    "    ax = axes[0]\n",
    "    g = sns.heatmap(X_baseline, annot=True, fmt=\".3g\", ax=ax)\n",
    "    g.set_xlabel(\"roi\")\n",
    "    g.set_ylabel(\"sample id\")\n",
    "    g.set_title(\"baseline\")\n",
    "    ax = axes[1]\n",
    "    g = sns.heatmap(X_followup,annot=True, fmt=\".3g\", ax=ax)\n",
    "    g.set_title(\"followup\")\n",
    "    g.set_xlabel(\"roi\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "time_diff = abs(traj1[1:] - traj1[:-1])\n",
    "indiv_diff = abs(roi_1[:,0][1:] - roi_1[:,0][:-1])\n",
    "\n",
    "print(f\"time_diff mean: {np.mean(time_diff)}, std: {np.std(time_diff)}\")\n",
    "print(f\"indiv_diff mean: {np.mean(indiv_diff)}, std: {np.std(indiv_diff)}\")\n",
    "\n",
    "t_df = pd.DataFrame()\n",
    "i_df = pd.DataFrame()\n",
    "t_df[\"diff\"] = time_diff\n",
    "t_df[\"type\"] = \"time\"\n",
    "i_df[\"diff\"] = indiv_diff\n",
    "i_df[\"type\"] = \"indiv\"\n",
    "plot_df = t_df.append(i_df)\n",
    "\n",
    "sns.histplot(x=\"diff\",bins=100,hue=\"type\",data=plot_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run entire toy example"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Traj params (Fixed)\n",
    "\n",
    "\n",
    "traj_func_list = [\"exp\", \"poly\"]\n",
    "roi_variation_list = [\"roi_init\", \"roi_time\"]\n",
    "\n",
    "subject_variation_list = [0.5]\n",
    "followup_list = [2]\n",
    "n_iterations = 1\n",
    "data_aug = True\n",
    "\n",
    "n_timepoints = 100\n",
    "n_samples_list = [100]\n",
    "n_regions_list = [10]\n",
    "\n",
    "lr = 0.001\n",
    "batch_size = 25\n",
    "n_epochs = 100\n",
    "hidden_node_list = [10,25]\n",
    "n_jobs = 4\n",
    "\n",
    "perf_df = pd.DataFrame()\n",
    "\n",
    "for it in np.arange(n_iterations):\n",
    "    for traj_func in traj_func_list:\n",
    "        for roi_variation in roi_variation_list:            \n",
    "            for subject_variation in subject_variation_list:\n",
    "                for followup_interval in followup_list:\n",
    "                    for n_samples in n_samples_list:\n",
    "                        for n_regions in n_regions_list: \n",
    "                            # Model configs (need to initialized for each data config)\n",
    "                            model_dict = {\n",
    "                                \"Ridge\": Ridge(), \n",
    "                                \"RF\": RandomForestRegressor(n_jobs=n_jobs, random_state=1), \n",
    "                                # \"GB\": GradientBoostingRegressor(random_state=1)\n",
    "                                \"LSN\": None,\n",
    "                                # \"LSN1\": None,\n",
    "                                # \"LSN2\": None,\n",
    "                                # \"LSN3\": None\n",
    "                            }\n",
    "                            traj_list = get_trajectories(traj_func, roi_variation, n_timepoints, n_regions)\n",
    "\n",
    "                            # Get roi samples\n",
    "                            roi_list = [get_traj_samples(traj, n_samples, subject_variation) for traj in traj_list]\n",
    "\n",
    "                            # Get cross-sectional time data (sample with replacement)\n",
    "                            y_baseline, X_baseline, X_followup = get_cross_sectional_samples(roi_list, followup_interval=followup_interval)\n",
    "\n",
    "                            # normalize y\n",
    "                            y_followup = y_baseline + followup_interval\n",
    "                            y_baseline = y_baseline/100\n",
    "                            y_followup = y_followup/100\n",
    "\n",
    "                            if followup_interval > 0:                \n",
    "                                X = np.hstack([X_baseline,X_followup])\n",
    "                                y = np.vstack([y_baseline,y_followup]).T\n",
    "                            else:\n",
    "                                X = X_baseline\n",
    "                                y = y_baseline\n",
    "                                \n",
    "                            # Split for CV and held-out test set\n",
    "                            n_CV = int(0.75 * len(y))\n",
    "\n",
    "                            X_CV = X[:n_CV]\n",
    "                            X_test = X[n_CV:]\n",
    "                            y_CV = y[:n_CV]\n",
    "                            y_test = y[n_CV:]\n",
    "\n",
    "                            if data_aug & (followup_interval > 0) :\n",
    "                                X_baseline_CV = X_baseline[:n_CV]\n",
    "                                X_followup_CV = X_followup[:n_CV]\n",
    "                                y_baseline_CV = y_baseline[:n_CV]\n",
    "                                y_followup_CV = y_followup[:n_CV]\n",
    "\n",
    "                                X_CV, y_CV = augment_data(X_baseline_CV, X_followup_CV, y_baseline_CV, y_followup_CV)\n",
    "\n",
    "\n",
    "                            # Run Models\n",
    "                            for model_name, model_instance in model_dict.items():\n",
    "                                print(f\"\\nSim config: iter: {it}, subject_variation: {subject_variation}, followup: {followup_interval}, \\\n",
    "                                        n_samples: {n_samples}, n_regions= {n_regions}, model: {model_name}, \\\n",
    "                                        traj func type: {traj_func}, shift param: {roi_variation}, data_aug: {data_aug}\")\n",
    "\n",
    "                                if model_name in [\"LSN\",\"LSN1\",\"LSN2\",\"LSN3\"]:                                            \n",
    "                                    trained_model_list = []\n",
    "                                    train_loss_list = []\n",
    "                                    for hidden_size in hidden_node_list:\n",
    "                                        if followup_interval > 0:\n",
    "                                            train_dataset = SimDataset(X_CV[:,:n_regions], X_CV[:,n_regions:], y_CV[:,0], y_CV[:,1])\n",
    "                                            train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                                        \n",
    "                                            model = LSN(X_baseline.shape[1],hidden_size=hidden_size) # alternative toy model: LSN()\n",
    "                                            model.train()\n",
    "\n",
    "                                            optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.5)                                                                                               \n",
    "                                            criterion = nn.MSELoss()                        \n",
    "\n",
    "                                            model, batch_loss_df, epoch_loss_df = train(model,train_dataloader,optimizer,criterion,n_epochs)\n",
    "                                        else:\n",
    "                                            train_dataset = SimpleSimDataset(X_CV, y_CV)\n",
    "                                            train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                                        \n",
    "                                            model = simpleFF(X_CV.shape[1], hidden_size=hidden_size)\n",
    "                                            model.train()\n",
    "\n",
    "                                            optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.5)                                                                                               \n",
    "                                            criterion = nn.MSELoss()                        \n",
    "\n",
    "                                            model, batch_loss_df, epoch_loss_df = trainSimpleFF(model,train_dataloader,optimizer,criterion,n_epochs)                            \n",
    "\n",
    "                                        train_loss = epoch_loss_df[\"epoch_loss\"].values[-1]\n",
    "                                        train_loss_list.append(train_loss)\n",
    "                                        trained_model_list.append(model)\n",
    "                                        \n",
    "                                    # pick the best model\n",
    "                                    opt_model_idx = np.argmin(train_loss_list)\n",
    "                                    train_loss = np.min(train_loss_list)\n",
    "                                    model = trained_model_list[opt_model_idx]\n",
    "\n",
    "                                    # test\n",
    "                                    if followup_interval > 0:\n",
    "                                        test_dataset = SimDataset(X_test[:,:n_regions], X_test[:,n_regions:], y_test[:,0], y_test[:,1])\n",
    "                                        test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "                                        model.eval()                    \n",
    "                                        batch_pred_list, test_MAE1, test_MAE2 = test(model, test_dataloader)\n",
    "                                        y_pred = np.vstack(np.squeeze(batch_pred_list))\n",
    "                                        \n",
    "                                        test_r1 = stats.pearsonr(y_pred[:,0],y_test[:,0])[0]\n",
    "                                        test_r2 = stats.pearsonr(y_pred[:,1],y_test[:,1])[0]   \n",
    "\n",
    "                                        test_age_1 = 100*y_test[:,0]\n",
    "                                        test_age_2 = 100*y_test[:,1]\n",
    "\n",
    "                                        test_brainage_1 = y_pred[:,0] # for two timepoints y is a matrix\n",
    "                                        test_brainage_2 = y_pred[:,1]\n",
    "\n",
    "                                    else:\n",
    "                                        test_dataset = SimpleSimDataset(X_test, y_test)\n",
    "                                        test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "                                        model.eval()                    \n",
    "                                        batch_pred_list, test_MAE1 = testSimpleFF(model, test_dataloader)\n",
    "                                        y_pred = np.squeeze(np.vstack(batch_pred_list))                                                                        \n",
    "                                        test_MAE2 = None\n",
    "                                        \n",
    "                                        test_r1 = stats.pearsonr(y_pred,y_test)[0]\n",
    "                                        test_r2 = None\n",
    "\n",
    "                                        test_age_1 = 100*y_test\n",
    "                                        test_age_2 = None\n",
    "\n",
    "                                        test_brainage_1 = y_pred # for single timepoint y is a vector\n",
    "                                        test_brainage_2 = None\n",
    "\n",
    "                                else:\n",
    "                                    CV_scores, y_pred, test_MAE1, test_MAE2, test_r1, test_r2 = get_brain_age_perf(X_CV, y_CV, X_test, y_test, model_instance)\n",
    "                                    train_loss = np.mean(-1*CV_scores) #negative MSE\n",
    "\n",
    "                                    if followup_interval > 0:\n",
    "                                        test_age_1 = y_test[:,0]\n",
    "                                        test_age_2 = y_test[:,1]\n",
    "                                        test_brainage_1 = y_pred[:,0]\n",
    "                                        test_brainage_2 = y_pred[:,1]\n",
    "                                    \n",
    "                                    else:\n",
    "                                        test_age_1 = y_test\n",
    "                                        test_age_2 = None\n",
    "                                        test_brainage_1 = y_pred\n",
    "                                        test_brainage_2 = None\n",
    "                                \n",
    "                                df = pd.DataFrame()\n",
    "                                df[\"eid\"] = np.arange(len(y_test))\n",
    "                                df[\"test_age_1\"] = test_age_1\n",
    "                                df[\"test_age_2\"] = test_age_2\n",
    "                                df[\"test_brainage_1\"] = test_brainage_1\n",
    "                                df[\"test_brainage_2\"] = test_brainage_2\n",
    "                                df[\"test_MAE1\"] = test_MAE1                    \n",
    "                                df[\"test_MAE2\"] = test_MAE2\n",
    "                                df[\"test_r1\"] = test_r1\n",
    "                                df[\"test_r2\"] = test_r2\n",
    "                                df[\"CV_score\"] = train_loss\n",
    "                                df[\"model\"] = model_name\n",
    "                                df[\"n_samples\"] = n_samples\n",
    "                                df[\"n_regions\"] = n_regions\n",
    "                                df[\"followup_interval\"] = followup_interval   \n",
    "                                df[\"subject_variation\"] = subject_variation\n",
    "                                df[\"traj_func\"] = traj_func\n",
    "                                df[\"roi_variation\"] = roi_variation\n",
    "                                df[\"data_aug\"] = data_aug\n",
    "                                df[\"iter\"] = it\n",
    "\n",
    "                                perf_df = perf_df.append(df)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f\"perf df shape: {perf_df.shape}, expected: {4*0.25*(it+1)*np.sum(n_samples_list)*len(subject_variation_list)*len(model_dict)*len(n_regions_list)*len(followup_list)}\")\n",
    "perf_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot MAE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if n_iterations > 1:\n",
    "    plot_df = perf_df.groupby([\"model\", \"n_samples\", \"n_regions\", \"followup_interval\", \"subject_variation\", \"iter\"]).mean().reset_index().copy()\n",
    "else:\n",
    "    plot_df = perf_df.copy()\n",
    "\n",
    "\n",
    "func_type = \"exp\"\n",
    "shift_param = \"roi_time\"\n",
    "intersubject_std = 0.5\n",
    "followup_interval = 2\n",
    "\n",
    "plot_df[\"plot_col\"] = \"traj shape: \" + plot_df['traj_func'] + \" \" + plot_df['roi_variation'] + \\\n",
    "                      \"\\nsubject variation: \" + plot_df['subject_variation'].astype(str) + \" \" + \\\n",
    "                      \"followup interval: \" + plot_df['followup_interval'].astype(str) + \"\\n n_regions: \" + plot_df['n_regions'].astype(str)\n",
    "\n",
    "# plot_df = plot_df[(plot_df[\"traj_func\"]==func_type) & (plot_df[\"roi_variation\"]==shift_param)] \n",
    "# plot_df = plot_df[(plot_df[\"subject_variation\"]==subject_variation) & (plot_df[\"followup_interval\"]==followup_interval)]\n",
    "\n",
    "plot_df[\"test_MAE\"] = 0.5 * (plot_df[\"test_MAE1\"] + plot_df[\"test_MAE1\"])\n",
    "plot_df[\"test_r\"] = 0.5 * (plot_df[\"test_r1\"] +plot_df[\"test_r1\"])\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.catplot(y=\"test_MAE\",x=\"n_samples\",hue=\"model\",col=\"plot_col\",col_wrap=4, kind=\"point\", data=plot_df, aspect=2, height=2, sharey=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot brainage diff"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_df[\"age_diff\"] = plot_df[\"test_age_2\"] - plot_df[\"test_age_1\"]\n",
    "plot_df[\"brainage_diff\"] = plot_df[\"test_brainage_2\"] - plot_df[\"test_brainage_1\"]\n",
    "\n",
    "print(f\"Save string for followup: {followup_interval}\")\n",
    "print(f\"run2_brainage-diff_func_{func_type}_roi-var_{shift_param}_subject-var_{subject_variation}\")\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.catplot(y=\"brainage_diff\",x=\"n_samples\",hue=\"model\",col=\"plot_col\",col_wrap=4, kind=\"point\", data=plot_df, aspect=2, height=2, sharey=False)\n",
    "\n",
    "plot_df.groupby([\"traj_func\", \"roi_variation\",\"model\",\"n_regions\",\"n_samples\"])[\"test_MAE\",\"brainage_diff\",\"age_diff\"].mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot subject-var for given sample and regions sizes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_df = perf_df.copy()\n",
    "\n",
    "traj_func = \"poly\"\n",
    "roi_variation = \"roi_init\"\n",
    "# intersubject_std = 0.1\n",
    "# followup_interval = 2\n",
    "\n",
    "plot_df = plot_df[(plot_df[\"traj_func\"]==func_type) & (plot_df[\"roi_variation\"]==shift_param)] \n",
    "plot_df = plot_df[(plot_df[\"n_samples\"]==100) & (plot_df[\"n_regions\"]==10)] \n",
    "\n",
    "plot_df[\"test_MAE\"] = 0.5 * (plot_df[\"test_MAE1\"] + plot_df[\"test_MAE1\"])\n",
    "plot_df[\"test_r\"] = 0.5 * (plot_df[\"test_r1\"] + plot_df[\"test_r1\"])\n",
    "\n",
    "print(f\"Save string for followup: {followup_interval}\")\n",
    "# print(f\"run2_MAE_func_{traj_func}_roi-var_{roi_variation}_subject-var_{subject_variation}\")\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    g = sns.catplot(y=\"test_MAE\",x=\"subject_variation\",hue=\"model\",col=\"followup_interval\", kind=\"point\", data=plot_df, aspect=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# perf_df.to_csv(\"results/simulation/brain_diff_sim_twinmodels_data_aug_success_run.csv\")\n",
    "# \n",
    "# LSN_df = pd.read_csv(\"results/simulation/brain_diff_sim_LSN_run_1.csv\")\n",
    "# base_df = pd.read_csv(\"results/simulation/brain_diff_sim_basemodels_run_2.csv\")\n",
    "# LSN_df = perf_df.copy()\n",
    "\n",
    "plt.plot(epoch_loss_df)\n",
    "epoch_loss_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_df = perf_df.copy()\n",
    "func_type = \"exp\"\n",
    "shift_param = \"roi_init\"\n",
    "intersubject_std = 0.5\n",
    "followup_interval = 2\n",
    "n_samples = 1000\n",
    "n_regions = 1000\n",
    "\n",
    "plot_df = plot_df[(plot_df[\"traj_func\"]==traj_func) & (plot_df[\"roi_variation\"]==roi_variation)] \n",
    "plot_df = plot_df[(plot_df[\"subject_variation\"]==subject_variation) & (plot_df[\"followup_interval\"]==followup_interval)]\n",
    "plot_df = plot_df[(plot_df[\"n_samples\"]==n_samples) & (plot_df[\"n_regions\"]==n_regions)] \n",
    "\n",
    "plot_df = plot_df[plot_df[\"model\"].isin([\"Ridge\",\"RF\",\"LSN\"])]\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    g = sns.scatterplot(x=\"test_age_1\",y=\"test_brainage_1\",hue=\"model\", marker=\"x\", data=plot_df, ax=ax)\n",
    "    g = sns.scatterplot(x=\"test_age_2\",y=\"test_brainage_2\",hue=\"model\", marker=\"d\", data=plot_df, ax=ax)\n",
    "\n",
    "    ax.set_title(f\"Brainage(s)\\ntraj_func:{traj_func},roi-var:{roi_variation},subject-var:{subject_variation}\\nn_samples:{n_samples},n_regions:{n_regions}\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('green_compute': venv)"
  },
  "interpreter": {
   "hash": "96e4927380308772faf387ce1ad6de9eaed4a7d7aadcf2622a8269a7d5f191c8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}