{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to test out freesufer stats output without using freesurfer utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from freesurfer_stats import CorticalParcellationStats\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def move_legend(ax, new_loc, **kws):\n",
    "    old_legend = ax.legend_\n",
    "    handles = old_legend.legendHandles\n",
    "    labels = [t.get_text() for t in old_legend.get_texts()]\n",
    "    title = old_legend.get_title().get_text()\n",
    "    ax.legend(handles, labels, loc=new_loc, title=title, **kws)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dir = \"/home/nikhil/projects/brain_changes/brain-diff/metadata/\"\n",
    "\n",
    "# DKT\n",
    "ukbb_dkt_fields = f\"{metadata_dir}UKBB_FS_DKT_Fields.csv\"\n",
    "ukbb_dkt_ct_fields = f\"{metadata_dir}UKBB_DKT_CT_Fields.csv\"\n",
    "\n",
    "# ASEG\n",
    "ukbb_aseg_fields = f\"{metadata_dir}UKBB_FS_ASEG_Fields.csv\"\n",
    "ukbb_aseg_vol_fields = f\"{metadata_dir}UKBB_ASEG_vol_Fields.csv\"\n",
    "\n",
    "\n",
    "fs_output_dir = \"/home/nikhil/projects/QPN_processing/test_data/fmriprep/output/freesurfer-6.0.1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read DKT CT stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving stat measures here: .//DKTatlas_average_thickness.csv\n"
     ]
    }
   ],
   "source": [
    "stat_file = \"aparc.DKTatlas.stats\"\n",
    "stat_measure = \"average_thickness_mm\" \n",
    "save_dir = './'\n",
    "\n",
    "\n",
    "ukbb_dkt_ct_fields_df = pd.read_csv(ukbb_dkt_ct_fields)\n",
    "\n",
    "hemispheres = [\"lh\", \"rh\"]\n",
    "roi_ct_field_df_dict = {}\n",
    "\n",
    "subject_id_list = [\"sub-PD01369D713546\",\"sub-NIMHANS001\"]\n",
    "\n",
    "hemi_stat_measures_dict = {}\n",
    "for hemi in hemispheres:\n",
    "    stat_measure_df = pd.DataFrame()\n",
    "    for subject_id in subject_id_list:\n",
    "        fs_stats_dir = f\"{fs_output_dir}{subject_id}/stats/\"\n",
    "        stats = CorticalParcellationStats.read(f\"{fs_stats_dir}{hemi}.{stat_file}\").structural_measurements\n",
    "        \n",
    "        cols = [\"subject_id\"] + list(stats[\"structure_name\"].values)\n",
    "        vals = [subject_id] + list(stats[stat_measure].values)\n",
    "        \n",
    "        df = pd.DataFrame(columns=cols)\n",
    "        df.loc[0] = vals\n",
    "        stat_measure_df = pd.concat([stat_measure_df, df], axis=0)\n",
    "\n",
    "    # replace columns names with ukbb field IDs\n",
    "    roi_ct_field_df = ukbb_dkt_ct_fields_df[ukbb_dkt_ct_fields_df[\"hemi\"]==hemi][[\"Field ID\",\"roi\"]]\n",
    "    roi_ct_field_df[\"hemi\"] = hemi\n",
    "    roi_ct_field_id_dict = dict(zip(roi_ct_field_df[\"roi\"], roi_ct_field_df[\"Field ID\"]))\n",
    "    stat_measure_df = stat_measure_df.rename(columns=roi_ct_field_id_dict)\n",
    "    \n",
    "    hemi_stat_measures_dict[hemi] = stat_measure_df\n",
    "\n",
    "    roi_ct_field_df_dict[hemi] = roi_ct_field_df\n",
    "\n",
    "# merge left and right dfs\n",
    "stat_measure_LR_df = pd.merge(hemi_stat_measures_dict[\"lh\"],hemi_stat_measures_dict[\"rh\"], on=\"subject_id\")\n",
    "\n",
    "save_file = f\"{stat_file.split('.')[1]}_{stat_measure.rsplit('_',1)[0]}.csv\"\n",
    "\n",
    "print(f\"Saving stat measures here: {save_dir}/{save_file}\")\n",
    "stat_measure_LR_df.to_csv(f\"{save_dir}/{save_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read ASEG vol stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_aseg(aseg_file, stat_measure):\n",
    "    aseg_data = np.loadtxt(aseg_file, dtype=\"i1,i1,i4,f4,S32,f4,f4,f4,f4,f4\")\n",
    "\n",
    "    aseg_df = pd.DataFrame(data=aseg_data)\n",
    "    aseg_df = aseg_df[[\"f4\",\"f3\"]].rename(columns={\"f3\":stat_measure, \"f4\":\"hemi_ROI\"})\n",
    "    aseg_df[\"hemi_ROI\"] = aseg_df[\"hemi_ROI\"].str.decode('utf-8') \n",
    "\n",
    "    print(f\"number of ROIs in aseg file: {len(aseg_df)}\")\n",
    "\n",
    "    return aseg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_file = \"aseg.stats\"\n",
    "stat_measure = \"Volume_mm3\"\n",
    "\n",
    "stat_measure_df = pd.DataFrame()\n",
    "for subject_id in subject_id_list:\n",
    "    fs_stats_dir = f\"{fs_output_dir}{subject_id}/stats/\"\n",
    "    aseg_file = f\"{fs_stats_dir}{stat_file}\"\n",
    "    stats = parse_aseg(aseg_file,stat_measure)\n",
    "    \n",
    "    cols = [\"subject_id\"] + list(stats[\"hemi_ROI\"].values)\n",
    "    vals = [subject_id] + list(stats[stat_measure].values)\n",
    "    \n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    df.loc[0] = vals\n",
    "    stat_measure_df = pd.concat([stat_measure_df, df], axis=0)\n",
    "\n",
    "# Grab UKBB field ids lookup table\n",
    "ukbb_aseg_vol_fields_df = pd.read_csv(ukbb_aseg_vol_fields)\n",
    "\n",
    "roi_vol_field_df = ukbb_aseg_vol_fields_df[ukbb_aseg_vol_fields_df[\"hemi_ROI\"].isin(stat_measure_df.columns)]\n",
    "common_rois = list(roi_vol_field_df[\"hemi_ROI\"].values)\n",
    "roi_vol_field_id_dict = dict(zip(roi_vol_field_df[\"hemi_ROI\"], roi_vol_field_df[\"Field ID\"]))\n",
    "\n",
    "print(f\"Number of aseg vol ROIs after UKBB merge: {len(roi_vol_field_id_dict)}\")\n",
    "\n",
    "# Rename ROIs with ukbb ids (remove the ROIs which don't have ukbb ids)\n",
    "stat_measure_df = stat_measure_df[[\"subject_id\"] + common_rois].copy()\n",
    "stat_measure_df = stat_measure_df.rename(columns=roi_vol_field_id_dict)\n",
    "\n",
    "save_file = f\"aseg_subcortical_volumes.csv\"\n",
    "\n",
    "print(f\"Saving stat measures here: {save_dir}/{save_file}\")\n",
    "stat_measure_df.to_csv(f\"{save_dir}/{save_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DKT + ASEG columns --> UKBB ID list\n",
    "- This is list of input variable for UKBB and ADNI comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aseg_ukbb_ids_df = roi_vol_field_df[[\"Field ID\",\"hemi_ROI\"]].copy()\n",
    "# aseg_ukbb_ids_df[\"stat\"] = \"aseg\"\n",
    "\n",
    "# dkt_ukbb_ids_df = pd.concat([roi_ct_field_df_dict[\"lh\"],roi_ct_field_df_dict[\"rh\"]],axis=0)\n",
    "# dkt_ukbb_ids_df[\"hemi_ROI\"] = dkt_ukbb_ids_df[\"hemi\"] + \"-\" + dkt_ukbb_ids_df[\"roi\"]\n",
    "# dkt_ukbb_ids_df[\"stat\"] = \"DKT\"\n",
    "\n",
    "# brainage_fs_ukbb_field_ids_df = pd.concat([dkt_ukbb_ids_df[[\"Field ID\",\"hemi_ROI\",\"stat\"]], \n",
    "#                                             aseg_ukbb_ids_df[[\"Field ID\",\"hemi_ROI\",\"stat\"]]],axis=0)\n",
    "\n",
    "\n",
    "# brainage_fs_ukbb_field_ids_df.to_csv(f\"{metadata_dir}/brainage_fs_ukbb_field_ids.csv\")\n",
    "\n",
    "# brainage_fs_ukbb_field_ids_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot CT after collating stats\n",
    "\n",
    "Desikan-Killiany-Tourville Atlas\n",
    "Cortical Regions. Frontal pole, temporal pole, and “banks of the superior temporal sulcus” regions were removed as per the DKT protocol, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/nikhil/projects/brain_changes/data/\"\n",
    "metadata_dir = f\"{data_dir}adni/metadata\"\n",
    "\n",
    "adnimerge = f\"{metadata_dir}/ADNIMERGE.csv\"\n",
    "\n",
    "FS_stats_dir = f\"{data_dir}adni/imaging/freesurfer/\"\n",
    "BL_CT_file = f\"{FS_stats_dir}adni2_bl/DKTatlas_average_thickness.csv\"\n",
    "BL_ASEG_file = f\"{FS_stats_dir}adni2_bl/aseg_subcortical_volumes.csv\"\n",
    "FU_CT_file = f\"{FS_stats_dir}m24/DKTatlas_average_thickness.csv\"\n",
    "FU_ASEG_file = f\"{FS_stats_dir}m24/aseg_subcortical_volumes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of BL, CT subjects: 530, number of ROIs: 2 x 31.0\n",
      "Number of BL, ASEG subjects: 530, number of ROIs: 36\n",
      "Number of FU, CT subjects: 616, number of ROIs: 2 x 31.0\n",
      "Number of FU, ASEG subjects: 615, number of ROIs: 36\n",
      "Number unique subjects with CT and ASEG features\n",
      " BL: 530, FU: 615, dropped subjects: 1, BLandFU: 267\n"
     ]
    }
   ],
   "source": [
    "BL_CT_df = pd.read_csv(BL_CT_file).drop(columns=[\"Unnamed: 0\"]).set_index(\"subject_id\")\n",
    "BL_ASEG_df = pd.read_csv(BL_ASEG_file).drop(columns=[\"Unnamed: 0\"]).set_index(\"subject_id\")\n",
    "FU_CT_df = pd.read_csv(FU_CT_file).drop(columns=[\"Unnamed: 0\"]).set_index(\"subject_id\")\n",
    "FU_ASEG_df = pd.read_csv(FU_ASEG_file).drop(columns=[\"Unnamed: 0\"]).set_index(\"subject_id\")\n",
    "\n",
    "\n",
    "print(f\"Number of BL, CT subjects: {len(BL_CT_df)}, number of ROIs: 2 x {len(BL_CT_df.columns)/2}\")\n",
    "print(f\"Number of BL, ASEG subjects: {len(BL_ASEG_df)}, number of ROIs: {len(BL_ASEG_df.columns)}\")\n",
    "\n",
    "print(f\"Number of FU, CT subjects: {len(FU_CT_df)}, number of ROIs: 2 x {len(FU_CT_df.columns)/2}\")\n",
    "print(f\"Number of FU, ASEG subjects: {len(FU_ASEG_df)}, number of ROIs: {len(FU_ASEG_df.columns)}\")\n",
    "\n",
    "## Ensures the visit has both DKT and ASEG data\n",
    "BL_subjects = set(BL_CT_df.index) & set(BL_ASEG_df.index)\n",
    "FU_subjects = set(FU_CT_df.index) & set(FU_ASEG_df.index)\n",
    "\n",
    "BL_and_FU_subjects = list(BL_subjects & FU_subjects)\n",
    "\n",
    "## Some outlier that need to be looked at (most likely proc failures)\n",
    "drop_subjects = [\"sub-ADNI082S4244\"] #sub-ADNI082S4244 --> super low inter-visit correlation\n",
    "\n",
    "for ds in drop_subjects:\n",
    "    BL_and_FU_subjects.remove(ds)\n",
    "\n",
    "print(f\"Number unique subjects with CT and ASEG features\\n BL: {len(BL_subjects)}, \\\n",
    "FU: {len(FU_subjects)}, dropped subjects: {len(drop_subjects)}, BLandFU: {len(BL_and_FU_subjects)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADNIMERGE len: 11483\n",
      "adnimerge with longitudinal subjects. n_subjects = 267\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>DX_bl</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>VISCODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3406</th>\n",
       "      <td>sub-ADNI072S4007</td>\n",
       "      <td>EMCI</td>\n",
       "      <td>78.1</td>\n",
       "      <td>Male</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426</th>\n",
       "      <td>sub-ADNI012S4026</td>\n",
       "      <td>CN</td>\n",
       "      <td>73.5</td>\n",
       "      <td>Male</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>sub-ADNI037S4028</td>\n",
       "      <td>CN</td>\n",
       "      <td>63.5</td>\n",
       "      <td>Female</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>sub-ADNI031S4032</td>\n",
       "      <td>CN</td>\n",
       "      <td>70.2</td>\n",
       "      <td>Female</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>sub-ADNI023S4035</td>\n",
       "      <td>LMCI</td>\n",
       "      <td>72.6</td>\n",
       "      <td>Female</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            subject_id DX_bl   AGE PTGENDER VISCODE\n",
       "3406  sub-ADNI072S4007  EMCI  78.1     Male      bl\n",
       "3426  sub-ADNI012S4026    CN  73.5     Male      bl\n",
       "3430  sub-ADNI037S4028    CN  63.5   Female      bl\n",
       "3439  sub-ADNI031S4032    CN  70.2   Female      bl\n",
       "3447  sub-ADNI023S4035  LMCI  72.6   Female      bl"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adnimerge_df = pd.read_csv(adnimerge)\n",
    "print(f\"ADNIMERGE len: {len(adnimerge_df)}\")\n",
    "\n",
    "adnimerge_df[\"subject_id\"] = \"sub-ADNI\" + adnimerge_df[\"PTID\"]\n",
    "adnimerge_df[\"subject_id\"] = adnimerge_df[\"subject_id\"].str.replace(\"_\",\"\")\n",
    "\n",
    "useful_cols = [\"subject_id\",\"DX_bl\",\"AGE\",\"PTGENDER\",\"VISCODE\"]\n",
    "adnimerge_dx_df = adnimerge_df[(adnimerge_df[\"subject_id\"].isin(BL_and_FU_subjects)) & (adnimerge_df[\"VISCODE\"]==\"bl\")][useful_cols]\n",
    "\n",
    "print(f\"adnimerge with longitudinal subjects. n_subjects = {len(adnimerge_dx_df)}\")\n",
    "adnimerge_dx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects with two visit data: 267\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>27174</th>\n",
       "      <th>27175</th>\n",
       "      <th>27176</th>\n",
       "      <th>27177</th>\n",
       "      <th>27178</th>\n",
       "      <th>27179</th>\n",
       "      <th>27180</th>\n",
       "      <th>27181</th>\n",
       "      <th>27182</th>\n",
       "      <th>...</th>\n",
       "      <th>27289</th>\n",
       "      <th>27290</th>\n",
       "      <th>27291</th>\n",
       "      <th>27292</th>\n",
       "      <th>27293</th>\n",
       "      <th>27294</th>\n",
       "      <th>27295</th>\n",
       "      <th>27296</th>\n",
       "      <th>27297</th>\n",
       "      <th>DX_bl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-ADNI019S4285</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>0.151</td>\n",
       "      <td>EMCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-ADNI116S4453</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.089</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.111</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-ADNI116S4625</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.011</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-ADNI011S4893</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.092</td>\n",
       "      <td>EMCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-ADNI037S4410</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         subject_id  27174  27175  27176  27177  27178  27179  27180  27181  \\\n",
       "0  sub-ADNI019S4285  0.102  0.068  0.015 -0.280  0.024 -0.027  0.079  0.089   \n",
       "1  sub-ADNI116S4453 -0.080  0.089 -0.037  0.416  0.159  0.001 -0.005 -0.044   \n",
       "2  sub-ADNI116S4625 -0.062  0.051  0.004  0.375  0.099 -0.115  0.155  0.159   \n",
       "3  sub-ADNI011S4893  0.064  0.063  0.018  0.269 -0.021  0.076  0.051  0.029   \n",
       "4  sub-ADNI037S4410  0.064 -0.025  0.113  0.121 -0.051 -0.062  0.015  0.022   \n",
       "\n",
       "   27182  ...  27289  27290  27291  27292  27293  27294  27295  27296  27297  \\\n",
       "0  0.012  ...  0.026 -0.005  0.067  0.067  0.001  0.049 -0.003 -0.172  0.151   \n",
       "1 -0.085  ...  0.039 -0.167 -0.003 -0.115  0.038  0.109  0.062  0.119  0.111   \n",
       "2 -0.058  ...  0.025  0.306 -0.103 -0.076 -0.076 -0.005  0.004 -0.020  0.011   \n",
       "3  0.010  ...  0.096 -0.071  0.007  0.014  0.091  0.077  0.078  0.047  0.092   \n",
       "4  0.006  ...  0.038 -0.018  0.006 -0.024 -0.017 -0.027  0.008 -0.003 -0.066   \n",
       "\n",
       "   DX_bl  \n",
       "0   EMCI  \n",
       "1     CN  \n",
       "2     AD  \n",
       "3   EMCI  \n",
       "4     CN  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BL_CT_df_subset = BL_CT_df.loc[BL_and_FU_subjects].copy()\n",
    "\n",
    "FU_CT_df_subset = FU_CT_df.loc[BL_and_FU_subjects].copy()\n",
    "\n",
    "CT_diff_df = BL_CT_df_subset - FU_CT_df_subset\n",
    "print(f\"Number of subjects with two visit data: {len(CT_diff_df)}\")\n",
    "\n",
    "CT_diff_df = pd.merge(CT_diff_df.reset_index(), adnimerge_dx_df[[\"subject_id\",\"DX_bl\"]], on=\"subject_id\")\n",
    "\n",
    "CT_diff_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save available adni longitudinal data into single CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adni_FS_DKT_csv = f\"{data_dir}adni/imaging/freesurfer/adni_followup_subset_DKT.csv\"\n",
    "# adni_FS_aseg_csv = f\"{data_dir}adni/imaging/freesurfer/adni_followup_subset_aseg.csv\"\n",
    "\n",
    "# # DKT (CT)\n",
    "# BL_CT_df_subset = BL_CT_df.loc[BL_and_FU_subjects].copy()\n",
    "# FU_CT_df_subset = FU_CT_df.loc[BL_and_FU_subjects].copy()\n",
    "\n",
    "# CT_cols = BL_CT_df_subset.columns\n",
    "# CT_cols_ses2 = list(CT_cols.astype(str) + \"-2.0\")\n",
    "# CT_cols_ses3 = list(CT_cols.astype(str) + \"-3.0\")\n",
    "\n",
    "# BL_CT_df_subset = BL_CT_df_subset.rename(columns=dict(zip(CT_cols,CT_cols_ses2)))\n",
    "# FU_CT_df_subset = FU_CT_df_subset.rename(columns=dict(zip(CT_cols,CT_cols_ses3)))\n",
    "\n",
    "# CT_subset_df = pd.concat([BL_CT_df_subset,FU_CT_df_subset],axis=1)\n",
    "# CT_subset_df.to_csv(adni_FS_DKT_csv)\n",
    "\n",
    "# # ASEG (vol)\n",
    "# BL_ASEG_df_subset = BL_ASEG_df.loc[BL_and_FU_subjects].copy()\n",
    "# FU_ASEG_df_subset = FU_ASEG_df.loc[BL_and_FU_subjects].copy()\n",
    "\n",
    "# aseg_cols = BL_ASEG_df_subset.columns\n",
    "# aseg_cols_ses2 = list(aseg_cols.astype(str) + \"-2.0\")\n",
    "# aseg_cols_ses3 = list(aseg_cols.astype(str) + \"-3.0\")\n",
    "\n",
    "# BL_ASEG_df_subset = BL_ASEG_df_subset.rename(columns=dict(zip(aseg_cols,aseg_cols_ses2)))\n",
    "# FU_ASEG_df_subset = FU_ASEG_df_subset.rename(columns=dict(zip(aseg_cols,aseg_cols_ses3)))\n",
    "\n",
    "# ASEG_subset_df = pd.concat([BL_ASEG_df_subset,FU_ASEG_df_subset],axis=1)\n",
    "# ASEG_subset_df.to_csv(adni_FS_aseg_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read UKBB fields \n",
    "- This is based on UKBB showcase\n",
    "- Only doing once and saving fieldIDs-ROIs csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DKT CT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukbb_dkt_fields_df = pd.read_csv(ukbb_dkt_fields)\n",
    "ukbb_dkt_fields_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab rows with specific stat measure of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_measure = \"Mean thickness\" \n",
    "ukbb_dkt_measure_df = ukbb_dkt_fields_df[ukbb_dkt_fields_df[\"Description\"].str.startswith(stat_measure)].copy()\n",
    "ukbb_dkt_measure_df[\"Description\"] = ukbb_dkt_measure_df[\"Description\"].str.replace(\"Mean thickness\",\"Mean_thickness\")\n",
    "print(f\"number of fields with {stat_measure}: {len(ukbb_dkt_measure_df)}\")\n",
    "\n",
    "ukbb_dkt_measure_df[[\"metric\",\"roi\",\"hemi\"]] = ukbb_dkt_measure_df[\"Description\"].str.split(\" \", expand=True)[[0,2,3]]\n",
    "ukbb_dkt_measure_df[\"hemi\"] = ukbb_dkt_measure_df[\"hemi\"].replace({\"(left\":\"lh\", \"(right\":\"rh\"})\n",
    "ukbb_dkt_measure_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save \n",
    "# UKBB_dkt_ct_fields = \"/home/nikhil/projects/brain_changes/brain-diff/metadata/UKBB_DKT_CT_Fields.csv\"\n",
    "# ukbb_dkt_measure_df.to_csv(UKBB_dkt_ct_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASEG Vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukbb_aseg_fields_df = pd.read_csv(ukbb_aseg_fields)\n",
    "print(f\"Number of fields: {len(ukbb_aseg_fields_df)}\")\n",
    "ukbb_aseg_fields_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab rows with specific stat measure of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_measure = \"Volume of\" \n",
    "ukbb_aseg_fields_df = ukbb_aseg_fields_df[ukbb_aseg_fields_df[\"Description\"].str.startswith(stat_measure)].copy()\n",
    "ukbb_aseg_fields_df[\"Description\"] = ukbb_aseg_fields_df[\"Description\"].str.replace(\"Mean thickness\",\"Mean_thickness\")\n",
    "print(f\"number of fields with {stat_measure}: {len(ukbb_aseg_fields_df)}\")\n",
    "\n",
    "ukbb_aseg_fields_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukbb_aseg_fields_df[[\"metric\",\"roi\",\"hemi\"]] = ukbb_aseg_fields_df[\"Description\"].str.split(\" \", expand=True)[[0,2,3]]\n",
    "ukbb_aseg_fields_df[\"hemi\"] = ukbb_aseg_fields_df[\"hemi\"].replace({\"(left\":\"Left-\", \"(right\":\"Right-\", \"(whole\":\"\"})\n",
    "ukbb_aseg_fields_df[\"hemi_ROI\"] = ukbb_aseg_fields_df[\"hemi\"] + ukbb_aseg_fields_df[\"roi\"]\n",
    "ukbb_aseg_fields_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save \n",
    "# ukbb_aseg_vol_fields = \"/home/nikhil/projects/brain_changes/brain-diff/metadata/UKBB_ASEG_vol_Fields.csv\"\n",
    "# ukbb_aseg_fields_df.to_csv(ukbb_aseg_vol_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "999c495fe9dc36b558f9181c52eb411f8d79bcfd8fb93141da57ede7d0ce5d9c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('green_compute')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
